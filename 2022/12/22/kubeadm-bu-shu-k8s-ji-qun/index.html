<!DOCTYPE html><html class="theme-next gemini use-motion" lang="zh-Hans"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=1"><script src="//cdn.bootcss.com/pace/1.0.2/pace.min.js"></script><link href="//cdn.bootcss.com/pace/1.0.2/themes/pink/pace-theme-flash.css" rel="stylesheet"><script></script><meta name="theme-color" content="#222"><style>.pace .pace-progress{background:#1e92fb;height:3px}.pace .pace-progress-inner{box-shadow:0 0 10px #1e92fb,0 0 5px #1e92fb}.pace .pace-activity{border-top-color:#1e92fb;border-left-color:#1e92fb}</style><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><meta name="google-site-verification" content="HGM141IpbHrSmnAmR6W_zE4bo9Z3f-yXLeHYT3bg1fk"><meta name="baidu-site-verification" content="code-5Ai1DA8e6T"><link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css"><link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css"><link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css"><link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4"><link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.4"><link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4"><link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222"><meta name="keywords" content="kubernetes - kubeadm,"><link rel="alternate" href="/atom.xml" title="凡间的精灵" type="application/atom+xml"><meta name="description" content="kubeadm部署k8s集群k8s集群环境规划主机名IP地址节点作用k8s 相关组件k8s-master192.168.223.140k8s-masterkubeadmin，kube-apiserver，kube-controller-manager，kube-scheduler，etcd，kube-proxy，kubeletk8s-node1192.168.223.142k8s-node1kub"><meta name="keywords" content="kubernetes - kubeadm"><meta property="og:type" content="article"><meta property="og:title" content="kubeadm部署k8s集群"><meta property="og:url" content="http:&#x2F;&#x2F;chenzhonzhou.github.io&#x2F;2022&#x2F;12&#x2F;22&#x2F;kubeadm-bu-shu-k8s-ji-qun&#x2F;index.html"><meta property="og:site_name" content="凡间的精灵"><meta property="og:description" content="kubeadm部署k8s集群k8s集群环境规划主机名IP地址节点作用k8s 相关组件k8s-master192.168.223.140k8s-masterkubeadmin，kube-apiserver，kube-controller-manager，kube-scheduler，etcd，kube-proxy，kubeletk8s-node1192.168.223.142k8s-node1kub"><meta property="og:locale" content="zh-Hans"><meta property="og:updated_time" content="2023-12-02T02:42:48.196Z"><meta name="twitter:card" content="summary"><script type="text/javascript" id="hexo.configurations">var NexT=window.NexT||{},CONFIG={root:"/",scheme:"Gemini",version:"5.1.4",sidebar:{position:"left",display:"always",offset:12,b2t:!0,scrollpercent:!0,onmobile:!0},fancybox:!0,tabs:!0,motion:{enable:!0,async:!1,transition:{post_block:"fadeIn",post_header:"slideDownIn",post_body:"slideDownIn",coll_header:"slideLeftIn",sidebar:"slideUpIn"}},duoshuo:{userId:"0",author:"博主"},algolia:{applicationID:"",apiKey:"",indexName:"",hits:{per_page:10},labels:{input_placeholder:"Search for Posts",hits_empty:"We didn't find any results for the search: ${query}",hits_stats:"${hits} results found in ${time} ms"}}}</script><link rel="canonical" href="http://chenzhonzhou.github.io/2022/12/22/kubeadm-bu-shu-k8s-ji-qun/"><title>kubeadm部署k8s集群 | 凡间的精灵</title><link rel="stylesheet" href="/css/prism-tomorrow.css" type="text/css"></head><body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans"><div class="container sidebar-position-left page-post-detail"><div class="headband"></div><header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="header-inner"><div class="site-brand-wrapper"><div class="site-meta"><div class="custom-logo-site-title"><a href="/" class="brand" rel="start"><span class="logo-line-before"><i></i></span> <span class="site-title">凡间的精灵</span><span class="logo-line-after"><i></i></span></a></div><p class="site-subtitle">凡尘落素一精灵</p></div><div class="site-nav-toggle"><button><span class="btn-bar"></span><span class="btn-bar"></span><span class="btn-bar"></span></button></div></div><nav class="site-nav"><ul id="menu" class="menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="menu-item-icon fa fa-fw fa-home"></i><br>首页</a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="menu-item-icon fa fa-fw fa-archive"></i><br>归档</a></li><li class="menu-item menu-item-categories"><a href="/categories" rel="section"><i class="menu-item-icon fa fa-fw fa-th"></i><br>分类</a></li><li class="menu-item menu-item-tags"><a href="/tags" rel="section"><i class="menu-item-icon fa fa-fw fa-tags"></i><br>标签</a></li><li class="menu-item menu-item-sitemap"><a href="/sitemap.xml" rel="section"><i class="menu-item-icon fa fa-fw fa-sitemap"></i><br>站点地图</a></li><li class="menu-item menu-item-search"><a href="javascript:;" class="popup-trigger"><i class="menu-item-icon fa fa-search fa-fw"></i><br>搜索</a></li></ul><div class="site-search"><div class="popup search-popup local-search-popup"><div class="local-search-header clearfix"><span class="search-icon"><i class="fa fa-search"></i></span><span class="popup-btn-close"><i class="fa fa-times-circle"></i></span><div class="local-search-input-wrapper"><input autocomplete="off" placeholder="搜索..." spellcheck="false" type="text" id="local-search-input"></div></div><div id="local-search-result"></div></div></div></nav></div></header><main id="main" class="main"><div class="main-inner"><div class="content-wrap"><div id="content" class="content"><div id="posts" class="posts-expand"><article class="post post-type-normal" itemscope itemtype="http://schema.org/Article"><div class="post-block"><link itemprop="mainEntityOfPage" href="http://chenzhonzhou.github.io/2022/12/22/kubeadm-bu-shu-k8s-ji-qun/"><span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="name" content="Zhongzhou Chen"><meta itemprop="description" content=""><meta itemprop="image" content="/images/chen.png"></span><span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="凡间的精灵"></span><header class="post-header"><h1 class="post-title" itemprop="name headline">kubeadm部署k8s集群</h1><div class="post-meta"><span class="post-time"><span class="post-meta-item-icon"><i class="fa fa-calendar-o"></i></span> <span class="post-meta-item-text">发表于</span> <time title="创建于" itemprop="dateCreated datePublished" datetime="2022-12-22T10:37:34+08:00">2022-12-22</time></span> <span class="post-category"><span class="post-meta-divider">|</span><span class="post-meta-item-icon"><i class="fa fa-folder-o"></i></span> <span class="post-meta-item-text">分类于</span> <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/kubernetes/" itemprop="url" rel="index"><span itemprop="name">kubernetes</span></a></span></span><div class="post-wordcount"><span class="post-meta-item-icon"><i class="fa fa-file-word-o"></i></span> <span class="post-meta-item-text">字数统计&#58;</span> <span title="字数统计">5.9k</span> <span class="post-meta-divider">|</span><span class="post-meta-item-icon"><i class="fa fa-clock-o"></i></span> <span class="post-meta-item-text">阅读时长 &asymp;</span> <span title="阅读时长">30</span></div></div></header><div class="post-body" itemprop="articleBody"><h1 id="kubeadm部署k8s集群"><a href="#kubeadm部署k8s集群" class="headerlink" title="kubeadm部署k8s集群"></a>kubeadm部署k8s集群</h1><p>k8s集群环境规划</p><table><thead><tr><th>主机名</th><th>IP地址</th><th>节点作用</th><th>k8s 相关组件</th></tr></thead><tbody><tr><td>k8s-master</td><td>192.168.223.140</td><td>k8s-master</td><td>kubeadmin，kube-apiserver，kube-controller-manager，kube-scheduler，etcd，kube-proxy，kubelet</td></tr><tr><td>k8s-node1</td><td>192.168.223.142</td><td>k8s-node1</td><td>kubeadmin，kube-proxy，kubelet</td></tr></tbody></table><h2 id="一、系统初始化配置"><a href="#一、系统初始化配置" class="headerlink" title="一、系统初始化配置"></a>一、系统初始化配置</h2><p>系统初始化配置在所有服务器上操作</p><p><strong>设置主机名</strong></p><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">[root@k8s-master ~]<span class="comment"># hostnamectl set-hostname k8s-master</span></span><br><span class="line">[root@k8s-node1 ~]<span class="comment"># hostnamectl set-hostname k8s-node1</span></span><br><span class="line"></span><br><span class="line"><span class="comment">## 设置master 节点hosts</span></span><br><span class="line">[root@k8s-master ~]<span class="comment"># vim /etc/hosts</span></span><br><span class="line">192.168.223.140 k8s-master</span><br><span class="line"></span><br><span class="line"><span class="comment">## node节点除了配置master hosts还要配置自己的hosts</span></span><br><span class="line">[root@k8s-node1 ~]<span class="comment"># vim /etc/hosts</span></span><br><span class="line">192.168.223.140 k8s-master</span><br><span class="line">192.168.223.142 k8s-node1</span><br></pre></td></tr></tbody></table></figure><p><strong>安装依赖包</strong></p><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># yum -y install conntrack ntpdate ntp ipvsadm ipset jq iptables curl sysstat libseccomp wget git vim net-tools</span></span><br></pre></td></tr></tbody></table></figure><p><strong>禁用firewalld</strong></p><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># systemctl stop firewalld &amp;&amp; systemctl disable firewalld</span></span><br></pre></td></tr></tbody></table></figure><p><strong>关闭swap分区和SELINUX</strong></p><p>如果不关闭，默认配置下kubelet将无法启动。使用free -m确认swap已经关闭。</p><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># swapoff -a &amp;&amp; sed -ri 's/.*swap.*/#&amp;/' /etc/fstab</span></span><br><span class="line"><span class="comment"># setenforce 0 &amp;&amp; sed -i 's/^SELINUX=.*/SELINUX=disabled/' /etc/selinux/config</span></span><br></pre></td></tr></tbody></table></figure><p><strong>调整时区</strong>并关闭系统不需要的服务</p><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># timedatectl set-timezone Asia/Shanghai &amp;&amp; timedatectl set-local-rtc 0</span></span><br><span class="line"><span class="comment"># systemctl start ntpd &amp;&amp; systemctl enable ntpd</span></span><br><span class="line"><span class="comment"># systemctl restart rsyslog &amp;&amp; systemctl restart crond</span></span><br><span class="line"><span class="comment"># systemctl stop postfix &amp;&amp; systemctl disable postfix</span></span><br></pre></td></tr></tbody></table></figure><p><strong>调整k8s内核参数</strong></p><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># cat &gt;  /etc/sysctl.d/kubernetes.conf&lt;&lt;EOF</span></span><br><span class="line"><span class="comment">#开启网桥模式【重要】</span></span><br><span class="line">net.bridge.bridge-nf-call-iptables=1</span><br><span class="line"><span class="comment">#开启网桥模式【重要】</span></span><br><span class="line">net.bridge.bridge-nf-call-ip6tables=1</span><br><span class="line">net.ipv4.ip_forward=1</span><br><span class="line">net.ipv4.tcp_tw_recycle=0</span><br><span class="line"><span class="comment">#禁止使用swap空间，只有当系统OOM时才允许使用它</span></span><br><span class="line">vm.swappiness=0</span><br><span class="line"><span class="comment">#不检查物理内存是否够用</span></span><br><span class="line">vm.overcommit_memory=1</span><br><span class="line"><span class="comment">#开启OOM</span></span><br><span class="line">vm.panic_on_oom=0</span><br><span class="line">fs.inotify.max_user_instances=8192</span><br><span class="line">fs.inotify.max_user_watches=1048576</span><br><span class="line">fs.file-max=52706963</span><br><span class="line">fs.nr_open=52706963</span><br><span class="line"><span class="comment">#关闭ipv6【重要】</span></span><br><span class="line">net.ipv6.conf.all.disable_ipv6=1</span><br><span class="line">net.netfilter.nf_conntrack_max=2310720</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line"><span class="comment"># sysctl --system</span></span><br></pre></td></tr></tbody></table></figure><p><strong>升级Linux内核为4.44版本</strong></p><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># rpm --import https://www.elrepo.org/RPM-GPG-KEY-elrepo.org</span></span><br><span class="line"><span class="comment"># rpm -Uvh http://www.elrepo.org/elrepo-release-7.0-2.el7.elrepo.noarch.rpm</span></span><br><span class="line"><span class="comment"># yum --disablerepo="*" --enablerepo="elrepo-kernel" list available</span></span><br><span class="line"><span class="comment"># yum --enablerepo=elrepo-kernel install kernel-ml</span></span><br><span class="line"><span class="comment"># cp /etc/default/grub  /etc/default/grub_bak</span></span><br><span class="line"><span class="comment"># grub2-mkconfig -o /boot/grub2/grub.cfg</span></span><br><span class="line"><span class="comment">##查看系统上的所有可用内核：</span></span><br><span class="line"><span class="comment"># awk -F\' '$1=="menuentry " {print i++ " : " $2}' /etc/grub2.cfg</span></span><br><span class="line">0 : CentOS Linux (6.1.2-1.el7.elrepo.x86_64) 7 (Core)</span><br><span class="line">1 : CentOS Linux (3.10.0-327.el7.x86_64) 7 (Core)</span><br><span class="line">2 : CentOS Linux (0-rescue-5643801f4d944842ae274438c9c18c90) 7 (Core)</span><br><span class="line"><span class="comment"># grub2-set-default 0</span></span><br><span class="line"><span class="comment"># reboot</span></span><br><span class="line"><span class="comment"># uname -a</span></span><br></pre></td></tr></tbody></table></figure><p><strong>kube-proxy开启ipvs</strong>的前置条件</p><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># modprobe br_netfilter</span></span><br><span class="line"><span class="comment"># cat &gt;/etc/sysconfig/modules/ipvs.modules &lt;&lt;EOF</span></span><br><span class="line"><span class="meta">#!/bin/bash</span></span><br><span class="line">modprobe -- ip_vs</span><br><span class="line">modprobe -- ip_vs_rr</span><br><span class="line">modprobe -- ip_vs_wrr</span><br><span class="line">modprobe -- ip_vs_sh</span><br><span class="line">modprobe -- nf_conntrack_ipv4</span><br><span class="line">EOF</span><br><span class="line"><span class="comment"># chmod 755 /etc/sysconfig/modules/ipvs.modules</span></span><br><span class="line"><span class="comment"># bash /etc/sysconfig/modules/ipvs.modules &amp;&amp; lsmod |grep -e ip_vs -e nf_conntrack_ipv4</span></span><br></pre></td></tr></tbody></table></figure><p>如果使用了较为高版本的内核这里可能会报错：<code>modprobe: FATAL: Module nf_conntrack_ipv4 not found.</code> 这是因为在高版本内核已经把 nf_conntrack_ipv4 替换为 nf_conntrack 了，改为 nf_conntrack 即可。</p><h2 id="二、安装docker"><a href="#二、安装docker" class="headerlink" title="二、安装docker"></a>二、安装docker</h2><p>一定要安装18.09版以上的docker，否则在初始化k8s master的时候会提示：<code>[WARNING SystemVerification]: this Docker version is not on the list of validated versions: 19.03.3. Latest validated version: 18.09</code></p><p><strong>所有服务器安装docker</strong></p><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># yum install -y yum-utils</span></span><br><span class="line"><span class="comment"># yum-config-manager --add-repo http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo</span></span><br><span class="line"><span class="comment"># yum makecache fast</span></span><br><span class="line"><span class="comment"># yum install -y docker-ce-19.03.0 docker-ce-cli-19.03.0 containerd.io</span></span><br><span class="line"><span class="comment"># systemctl start docker &amp;&amp; systemctl enable docker</span></span><br></pre></td></tr></tbody></table></figure><p>修改docker cgroup driver为systemd</p><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># cat &gt;/etc/docker/daemon.json &lt;&lt;EOF</span></span><br><span class="line">{</span><br><span class="line">  <span class="string">"exec-opts"</span>: [<span class="string">"native.cgroupdriver=systemd"</span>],</span><br><span class="line">  <span class="string">"log-driver"</span>: <span class="string">"json-file"</span></span><br><span class="line">}</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line"><span class="comment"># systemctl restart docker</span></span><br><span class="line"><span class="comment"># docker info | grep Cgroup</span></span><br><span class="line"> Cgroup Driver: systemd</span><br><span class="line"> Cgroup Version: 1</span><br></pre></td></tr></tbody></table></figure><h2 id="三、kubeadm安装k8s集群"><a href="#三、kubeadm安装k8s集群" class="headerlink" title="三、kubeadm安装k8s集群"></a>三、kubeadm安装k8s集群</h2><p><strong>配置k8s yum源</strong></p><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># cat &gt; /etc/yum.repos.d/kubernetes.repo &lt;&lt;EOF</span></span><br><span class="line">[kubernetes]</span><br><span class="line">name=Kubernetes</span><br><span class="line">baseurl=https://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64</span><br><span class="line">gpgcheck=0</span><br><span class="line">repo_gpgcheck=0</span><br><span class="line">gpgkey=https://mirrors.aliyun.com/kubernetes/yum/doc/yum-key.gpg https://mirrors.aliyun.com/kubernetes/yum/doc/rpm-package-key.gpg</span><br><span class="line">EOF</span><br></pre></td></tr></tbody></table></figure><h3 id="2-1-安装kubeadm，kubelet和kubectl"><a href="#2-1-安装kubeadm，kubelet和kubectl" class="headerlink" title="2.1 安装kubeadm，kubelet和kubectl"></a>2.1 安装kubeadm，kubelet和kubectl</h3><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># yum install -y kubelet-1.20.0 kubeadm-1.20.0 kubectl-1.20.0</span></span><br><span class="line"><span class="comment"># systemctl enable kubelet</span></span><br></pre></td></tr></tbody></table></figure><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">##查看初始化需要的镜像</span></span><br><span class="line"><span class="comment"># kubeadm config images list</span></span><br><span class="line">I0103 16:22:35.211779   23442 version.go:251] remote version is much newer: v1.26.0; falling back to: stable-1.20</span><br><span class="line">k8s.gcr.io/kube-apiserver:v1.20.15</span><br><span class="line">k8s.gcr.io/kube-controller-manager:v1.20.15</span><br><span class="line">k8s.gcr.io/kube-scheduler:v1.20.15</span><br><span class="line">k8s.gcr.io/kube-proxy:v1.20.15</span><br><span class="line">k8s.gcr.io/pause:3.2</span><br><span class="line">k8s.gcr.io/etcd:3.4.13-0</span><br><span class="line">k8s.gcr.io/coredns:1.7.0</span><br></pre></td></tr></tbody></table></figure><p>默认使用的镜像在国外仓库，后面我们可以改下载的仓库地址</p><h3 id="2-2-初始化master节点"><a href="#2-2-初始化master节点" class="headerlink" title="2.2 初始化master节点"></a>2.2 初始化master节点</h3><p>将默认的 init 初始化文件存放到指定位置</p><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@k8s-master ~]<span class="comment"># kubeadm config print init-defaults &gt; kubeadm-config.yml</span></span><br></pre></td></tr></tbody></table></figure><p><strong>编辑kubeadm-config.yaml</strong>，修改本机服务器IP（advertiseAddress）、版本号（kubernetesVersion）、添加国内镜像仓库（imageRepository）、pod网段（podSubnet）</p><figure class="highlight yaml"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">[root@k8s-master</span> <span class="string">~]#</span> <span class="string">cat</span> <span class="string">kubeadm-config.yaml</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">kubeadm.k8s.io/v1beta2</span></span><br><span class="line"><span class="attr">bootstrapTokens:</span></span><br><span class="line"><span class="attr">- groups:</span></span><br><span class="line"><span class="attr">  - system:</span><span class="attr">bootstrappers:kubeadm:default-node-token</span></span><br><span class="line"><span class="attr">  token:</span> <span class="string">abcdef.0123456789abcdef</span></span><br><span class="line"><span class="attr">  ttl:</span> <span class="number">24</span><span class="string">h0m0s</span></span><br><span class="line"><span class="attr">  usages:</span></span><br><span class="line"><span class="bullet">  -</span> <span class="string">signing</span></span><br><span class="line"><span class="bullet">  -</span> <span class="string">authentication</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">InitConfiguration</span></span><br><span class="line"><span class="attr">localAPIEndpoint:</span></span><br><span class="line"><span class="attr">  advertiseAddress:</span> <span class="number">192.168</span><span class="number">.223</span><span class="number">.140</span></span><br><span class="line"><span class="attr">  bindPort:</span> <span class="number">6443</span></span><br><span class="line"><span class="attr">nodeRegistration:</span></span><br><span class="line"><span class="attr">  criSocket:</span> <span class="string">/var/run/dockershim.sock</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">k8s-master</span></span><br><span class="line"><span class="attr">  taints:</span></span><br><span class="line"><span class="attr">  - effect:</span> <span class="string">NoSchedule</span></span><br><span class="line"><span class="attr">    key:</span> <span class="string">node-role.kubernetes.io/master</span></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="attr">apiServer:</span></span><br><span class="line"><span class="attr">  timeoutForControlPlane:</span> <span class="number">4</span><span class="string">m0s</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">kubeadm.k8s.io/v1beta2</span></span><br><span class="line"><span class="attr">certificatesDir:</span> <span class="string">/etc/kubernetes/pki</span></span><br><span class="line"><span class="attr">clusterName:</span> <span class="string">kubernetes</span></span><br><span class="line"><span class="attr">controllerManager:</span> <span class="string">{}</span></span><br><span class="line"><span class="attr">dns:</span></span><br><span class="line"><span class="attr">  type:</span> <span class="string">CoreDNS</span></span><br><span class="line"><span class="attr">etcd:</span></span><br><span class="line"><span class="attr">  local:</span></span><br><span class="line"><span class="attr">    dataDir:</span> <span class="string">/var/lib/etcd</span></span><br><span class="line"><span class="attr">imageRepository:</span> <span class="string">k8s.gcr.io</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">ClusterConfiguration</span></span><br><span class="line"><span class="attr">kubernetesVersion:</span> <span class="string">v1.20.0</span></span><br><span class="line"><span class="attr">imageRepository:</span> <span class="string">registry.cn-hangzhou.aliyuncs.com/google_containers</span></span><br><span class="line"><span class="attr">networking:</span></span><br><span class="line"><span class="attr">  dnsDomain:</span> <span class="string">cluster.local</span></span><br><span class="line"><span class="attr">  podSubnet:</span> <span class="string">"10.244.0.0/16"</span></span><br><span class="line"><span class="attr">  serviceSubnet:</span> <span class="number">10.96</span><span class="number">.0</span><span class="number">.0</span><span class="string">/12</span></span><br><span class="line"><span class="attr">scheduler:</span> <span class="string">{}</span></span><br></pre></td></tr></tbody></table></figure><p><strong>下载k8s-master节点镜像</strong></p><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@k8s-master ~]<span class="comment"># kubeadm config  images pull --config kubeadm-config.yml</span></span><br></pre></td></tr></tbody></table></figure><p><strong>初始化集群</strong></p><p>建议将集群初始化日志保存起来</p><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">[root@k8s-master ~]<span class="comment"># kubeadm init --config kubeadm-config.yml</span></span><br><span class="line">执行成功的结果……</span><br><span class="line">[kubelet-finalize] Updating <span class="string">"/etc/kubernetes/kubelet.conf"</span> to point to a rotatable kubelet client certificate and key</span><br><span class="line">[addons] Applied essential addon: CoreDNS</span><br><span class="line">[addons] Applied essential addon: kube-proxy</span><br><span class="line"></span><br><span class="line">Your Kubernetes control-plane has initialized successfully!</span><br><span class="line"></span><br><span class="line">To start using your cluster, you need to run the following as a regular user:</span><br><span class="line"></span><br><span class="line">  mkdir -p <span class="variable">$HOME</span>/.kube</span><br><span class="line">  sudo cp -i /etc/kubernetes/admin.conf <span class="variable">$HOME</span>/.kube/config</span><br><span class="line">  sudo chown $(id -u):$(id -g) <span class="variable">$HOME</span>/.kube/config</span><br><span class="line"></span><br><span class="line">Alternatively, <span class="keyword">if</span> you are the root user, you can run:</span><br><span class="line"></span><br><span class="line">  <span class="built_in">export</span> KUBECONFIG=/etc/kubernetes/admin.conf</span><br><span class="line"></span><br><span class="line">You should now deploy a pod network to the cluster.</span><br><span class="line">Run <span class="string">"kubectl apply -f [podnetwork].yaml"</span> with one of the options listed at:</span><br><span class="line">  https://kubernetes.io/docs/concepts/cluster-administration/addons/</span><br><span class="line"></span><br><span class="line">Then you can join any number of worker nodes by running the following on each as root:</span><br><span class="line"></span><br><span class="line">kubeadm join 192.168.223.140:6443 --token riz1na.4fhur5ubekjf4m0l \</span><br><span class="line">    --discovery-token-ca-cert-hash sha256:1f06697abdb74cdfc9601d32a45fcf636084bc7ba3de7180dacf97f1403a98c2</span><br></pre></td></tr></tbody></table></figure><p><strong>添加 kubectl 集群认证文件</strong></p><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[root@k8s-master ~]<span class="comment"># mkdir -p $HOME/.kube</span></span><br><span class="line">[root@k8s-master ~]<span class="comment"># cp -i /etc/kubernetes/admin.conf $HOME/.kube/config</span></span><br><span class="line">[root@k8s-master ~]<span class="comment"># chown $(id -u):$(id -g) $HOME/.kube/config</span></span><br></pre></td></tr></tbody></table></figure><p><strong>查看node节点</strong>（状态显示notready是因为还未部署网络插件）</p><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[root@k8s-master ~]<span class="comment"># kubectl get no</span></span><br><span class="line">NAME         STATUS     ROLES                  AGE   VERSION</span><br><span class="line">k8s-master   NotReady   control-plane,master   5m   v1.20.0</span><br></pre></td></tr></tbody></table></figure><h3 id="2-3-部署网络插件"><a href="#2-3-部署网络插件" class="headerlink" title="2.3 部署网络插件"></a>2.3 部署网络插件</h3><p>网络插件flannel 和 calico 二选一即可</p><h4 id="2-3-1-部署网络插件-flannel"><a href="#2-3-1-部署网络插件-flannel" class="headerlink" title="2.3.1 部署网络插件 flannel"></a>2.3.1 部署网络插件 flannel</h4><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@k8s-master ~]<span class="comment"># wget https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.yml</span></span><br><span class="line">[root@k8s-master ~]<span class="comment"># kubectl apply -f kube-flannel.yml</span></span><br></pre></td></tr></tbody></table></figure><p><strong>创建完成后查看pod的状态如下</strong></p><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">[root@k8s-master ~]<span class="comment"># kubectl get po -nkube-system</span></span><br><span class="line">NAME                                 READY   STATUS    RESTARTS   AGE</span><br><span class="line">coredns-7f89b7bc75-6qjmf             1/1     Running   0          12m</span><br><span class="line">coredns-7f89b7bc75-d5xv2             1/1     Running   0          12m</span><br><span class="line">etcd-k8s-master                      1/1     Running   0          12m</span><br><span class="line">kube-apiserver-k8s-master            1/1     Running   0          12m</span><br><span class="line">kube-controller-manager-k8s-master   1/1     Running   0          12m</span><br><span class="line">kube-proxy-fpf68                     1/1     Running   0          12m</span><br><span class="line">kube-scheduler-k8s-master            1/1     Running   0          12m</span><br></pre></td></tr></tbody></table></figure><p>等两分钟之后pod状态变成Running</p><p><strong>再查看node节点状态已经变成 ready</strong></p><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[root@k8s-master ~]<span class="comment"># kubectl get no</span></span><br><span class="line">NAME         STATUS   ROLES                  AGE   VERSION</span><br><span class="line">k8s-master   Ready    control-plane,master   14m   v1.20.0</span><br></pre></td></tr></tbody></table></figure><p><strong>开启ipvs转发模式</strong></p><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[root@k8s-master ~]<span class="comment"># kubectl edit configmaps -n kube-system kube-proxy</span></span><br><span class="line">kind: KubeProxyConfiguration</span><br><span class="line">    metricsBindAddress: <span class="string">""</span></span><br><span class="line">    mode: <span class="string">"ipvs"</span>  <span class="comment"># 填入`ipvs`</span></span><br><span class="line">    nodePortAddresses: null</span><br></pre></td></tr></tbody></table></figure><p>最后再加入node节点，通过<code>ipvsadm -Ln</code>查看</p><h4 id="2-3-2-部署网络插件-calico"><a href="#2-3-2-部署网络插件-calico" class="headerlink" title="2.3.2 部署网络插件 calico"></a>2.3.2 部署网络插件 calico</h4><p>前往<a href="https://projectcalico.docs.tigera.io/archive/v3.20/getting-started/kubernetes/requirements" target="_blank" rel="noopener">官网</a>查看 calico和k8s 版本对应关系，安装对应版本的calico</p><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@k8s-master ~]<span class="comment"># wget https://docs.projectcalico.org/v3.20/manifests/calico.yaml</span></span><br><span class="line">[root@k8s-master ~]<span class="comment"># kubectl apply -f calico.yaml</span></span><br></pre></td></tr></tbody></table></figure><p>等两分钟之后pod状态变成Running</p><p><strong>再查看node节点状态已经变成 ready</strong></p><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[root@k8s-master ~]<span class="comment"># kubectl get no</span></span><br><span class="line">NAME         STATUS   ROLES                  AGE   VERSION</span><br><span class="line">k8s-master   Ready    control-plane,master   58m   v1.20.0</span><br></pre></td></tr></tbody></table></figure><p><strong>开启ipvs转发模式</strong></p><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[root@k8s-master ~]<span class="comment"># kubectl edit configmaps -n kube-system kube-proxy</span></span><br><span class="line">kind: KubeProxyConfiguration</span><br><span class="line">    metricsBindAddress: <span class="string">""</span></span><br><span class="line">    mode: <span class="string">"ipvs"</span>  <span class="comment"># 填入`ipvs`</span></span><br><span class="line">    nodePortAddresses: null</span><br></pre></td></tr></tbody></table></figure><p>最后再加入node节点，通过<code>ipvsadm -Ln</code>查看</p><h3 id="2-4-node-节点加入集群"><a href="#2-4-node-节点加入集群" class="headerlink" title="2.4 node 节点加入集群"></a>2.4 node 节点加入集群</h3><p>使用初始化集群时生成的token，在node节点执行命令加入集群，默认token有效期为24小时，如果token过期了重新生成即可</p><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">[root@k8s-node1 ~]<span class="comment"># kubeadm join 192.168.223.140:6443 --token hpgvxz.q1iso7sfyoipqyp7     --discovery-token-ca-cert-hash sha256:1f06697abdb74cdfc9601d32a45fcf636084bc7ba3de7180dacf97f1403a98c2</span></span><br><span class="line">执行成功的结果……</span><br><span class="line">[preflight] Running pre-flight checks</span><br><span class="line">[preflight] Reading configuration from the cluster...</span><br><span class="line">[preflight] FYI: You can look at this config file with <span class="string">'kubectl -n kube-system get cm kubeadm-config -o yaml'</span></span><br><span class="line">[kubelet-start] Writing kubelet configuration to file <span class="string">"/var/lib/kubelet/config.yaml"</span></span><br><span class="line">[kubelet-start] Writing kubelet environment file with flags to file <span class="string">"/var/lib/kubelet/kubeadm-flags.env"</span></span><br><span class="line">[kubelet-start] Starting the kubelet</span><br><span class="line">[kubelet-start] Waiting <span class="keyword">for</span> the kubelet to perform the TLS Bootstrap...</span><br><span class="line"></span><br><span class="line">This node has joined the cluster:</span><br><span class="line">* Certificate signing request was sent to apiserver and a response was received.</span><br><span class="line">* The Kubelet was informed of the new secure connection details.</span><br><span class="line"></span><br><span class="line">Run <span class="string">'kubectl get nodes'</span> on the control-plane to see this node join the cluster.</span><br></pre></td></tr></tbody></table></figure><p>去master节点查看是否已加入集群</p><figure class="highlight plain"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[root@k8s-master ~]# kubectl get no</span><br><span class="line">NAME         STATUS   ROLES                  AGE   VERSION</span><br><span class="line">k8s-master   Ready    control-plane,master   33m   v1.20.0</span><br><span class="line">k8s-node1    Ready    &lt;none&gt;                 13s   v1.20.0</span><br></pre></td></tr></tbody></table></figure><h3 id="2-5-部署-nginx-测试"><a href="#2-5-部署-nginx-测试" class="headerlink" title="2.5 部署 nginx 测试"></a>2.5 部署 nginx 测试</h3><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">[root@k8s-master ~]<span class="comment"># kubectl create deploy nginx --image=nginx</span></span><br><span class="line">[root@k8s-master ~]<span class="comment"># kubectl get po -owide</span></span><br><span class="line">NAME                     READY   STATUS    RESTARTS   AGE   IP           NODE        NOMINATED NODE   READINESS GATES</span><br><span class="line">nginx-6799fc88d8-vngm5   1/1     Running   0          34s   10.244.1.2   k8s-node1   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">[root@k8s-master ~]<span class="comment"># curl -Ik 10.244.1.2</span></span><br><span class="line">HTTP/1.1 200 OK</span><br><span class="line">Server: nginx/1.21.5</span><br><span class="line">Date: Wed, 04 Jan 2023 06:12:48 GMT</span><br><span class="line">Content-Type: text/html</span><br><span class="line">Content-Length: 615</span><br><span class="line">Last-Modified: Tue, 28 Dec 2021 15:28:38 GMT</span><br><span class="line">Connection: keep-alive</span><br><span class="line">ETag: <span class="string">"61cb2d26-267"</span></span><br><span class="line">Accept-Ranges: bytes</span><br><span class="line"></span><br><span class="line">[root@k8s-master ~]<span class="comment"># kubectl delete deploy nginx</span></span><br></pre></td></tr></tbody></table></figure><h3 id="2-6-组件-Unhealthy-问题"><a href="#2-6-组件-Unhealthy-问题" class="headerlink" title="2.6 组件 Unhealthy 问题"></a>2.6 组件 Unhealthy 问题</h3><p>Kubeadm部署完 k8s集群后，scheduler和controller-manager为Unhealthy</p><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[root@k8s-master ~]<span class="comment"># kubectl get cs</span></span><br><span class="line">NAME                 STATUS      MESSAGE      ERROR</span><br><span class="line">controller-manager   Unhealthy   Get <span class="string">"http://127.0.0.1:10252/healthz"</span>: dial tcp 127.0.0.1:10252: connect: connection refused   </span><br><span class="line">scheduler            Unhealthy   Get <span class="string">"http://127.0.0.1:10251/healthz"</span>: dial tcp 127.0.0.1:10251: connect: connection refused   </span><br><span class="line">etcd-0               Healthy     {<span class="string">"health"</span>:<span class="string">"true"</span>}</span><br></pre></td></tr></tbody></table></figure><p>出现这种情况，是<code>/etc/kubernetes/manifests/</code>下的<code>kube-controller-manager.yaml</code>和<code>kube-scheduler.yaml</code>设置的默认端口是0导致的，解决方式是注释掉对应的port即可，操作如下：</p><p><strong>修改kube-controller-manager.yaml配置文件</strong>，将port=0注释</p><figure class="highlight yaml"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">[root@k8s-master</span> <span class="string">~]#</span> <span class="string">vim</span> <span class="string">/etc/kubernetes/manifests/kube-controller-manager.yaml</span></span><br><span class="line">  <span class="number">1</span> <span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line">  <span class="number">2</span> <span class="attr">kind:</span> <span class="string">Pod</span></span><br><span class="line">  <span class="number">3</span> <span class="attr">metadata:</span></span><br><span class="line">  <span class="number">4</span>   <span class="attr">creationTimestamp:</span> <span class="literal">null</span></span><br><span class="line">  <span class="number">5</span>   <span class="attr">labels:</span></span><br><span class="line">  <span class="number">6</span>     <span class="attr">component:</span> <span class="string">kube-controller-manager</span></span><br><span class="line">  <span class="number">7</span>     <span class="attr">tier:</span> <span class="string">control-plane</span></span><br><span class="line">  <span class="number">8</span>   <span class="attr">name:</span> <span class="string">kube-controller-manager</span></span><br><span class="line">  <span class="number">9</span>   <span class="attr">namespace:</span> <span class="string">kube-system</span></span><br><span class="line"> <span class="number">10</span> <span class="attr">spec:</span></span><br><span class="line"> <span class="number">11</span>   <span class="attr">containers:</span></span><br><span class="line"> <span class="number">12</span>   <span class="bullet">-</span> <span class="attr">command:</span></span><br><span class="line"> <span class="number">13</span>     <span class="bullet">-</span> <span class="string">kube-controller-manager</span></span><br><span class="line"> <span class="number">14</span>     <span class="bullet">-</span> <span class="bullet">--allocate-node-cidrs=true</span></span><br><span class="line"> <span class="number">15</span>     <span class="bullet">-</span> <span class="bullet">--authentication-kubeconfig=/etc/kubernetes/controller-manager.conf</span></span><br><span class="line"> <span class="number">16</span>     <span class="bullet">-</span> <span class="bullet">--authorization-kubeconfig=/etc/kubernetes/controller-manager.conf</span></span><br><span class="line"> <span class="number">17</span>     <span class="bullet">-</span> <span class="bullet">--bind-address=127.0.0.1</span></span><br><span class="line"> <span class="number">18</span>     <span class="bullet">-</span> <span class="bullet">--client-ca-file=/etc/kubernetes/pki/ca.crt</span></span><br><span class="line"> <span class="number">19</span>     <span class="bullet">-</span> <span class="bullet">--cluster-cidr=10.244.0.0/16</span></span><br><span class="line"> <span class="number">20</span>     <span class="bullet">-</span> <span class="bullet">--cluster-name=kubernetes</span></span><br><span class="line"> <span class="number">21</span>     <span class="bullet">-</span> <span class="bullet">--cluster-signing-cert-file=/etc/kubernetes/pki/ca.crt</span></span><br><span class="line"> <span class="number">22</span>     <span class="bullet">-</span> <span class="bullet">--cluster-signing-key-file=/etc/kubernetes/pki/ca.key</span></span><br><span class="line"> <span class="number">23</span>     <span class="bullet">-</span> <span class="bullet">--controllers=*,bootstrapsigner,tokencleaner</span></span><br><span class="line"> <span class="number">24</span>     <span class="bullet">-</span> <span class="bullet">--kubeconfig=/etc/kubernetes/controller-manager.conf</span></span><br><span class="line"> <span class="number">25</span>     <span class="bullet">-</span> <span class="bullet">--leader-elect=true</span></span><br><span class="line"> <span class="number">26</span>     <span class="comment">#- --port=0</span></span><br></pre></td></tr></tbody></table></figure><p><strong>修改kube-scheduler.yaml配置文件</strong>，将port=0注释掉</p><figure class="highlight yaml"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">[root@k8s-master</span> <span class="string">~]#</span> <span class="string">vim</span> <span class="string">/etc/kubernetes/manifests/kube-scheduler.yaml</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Pod</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">  creationTimestamp:</span> <span class="literal">null</span></span><br><span class="line"><span class="attr">  labels:</span></span><br><span class="line"><span class="attr">    component:</span> <span class="string">kube-scheduler</span></span><br><span class="line"><span class="attr">    tier:</span> <span class="string">control-plane</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">kube-scheduler</span></span><br><span class="line"><span class="attr">  namespace:</span> <span class="string">kube-system</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line"><span class="attr">  containers:</span></span><br><span class="line"><span class="attr">  - command:</span></span><br><span class="line"><span class="bullet">    -</span> <span class="string">kube-scheduler</span></span><br><span class="line"><span class="bullet">    -</span> <span class="bullet">--authentication-kubeconfig=/etc/kubernetes/scheduler.conf</span></span><br><span class="line"><span class="bullet">    -</span> <span class="bullet">--authorization-kubeconfig=/etc/kubernetes/scheduler.conf</span></span><br><span class="line"><span class="bullet">    -</span> <span class="bullet">--bind-address=127.0.0.1</span></span><br><span class="line"><span class="bullet">    -</span> <span class="bullet">--kubeconfig=/etc/kubernetes/scheduler.conf</span></span><br><span class="line"><span class="bullet">    -</span> <span class="bullet">--leader-elect=true</span></span><br><span class="line">    <span class="comment">#- --port=0</span></span><br></pre></td></tr></tbody></table></figure><p><strong>在master节点上重启kubelet</strong></p><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">[root@k8s-master ~]<span class="comment"># systemctl restart kubelet</span></span><br><span class="line">[root@k8s-master ~]<span class="comment"># kubectl get cs</span></span><br><span class="line">Warning: v1 ComponentStatus is deprecated <span class="keyword">in</span> v1.19+</span><br><span class="line">NAME                 STATUS    MESSAGE             ERROR</span><br><span class="line">controller-manager   Healthy   ok                  </span><br><span class="line">scheduler            Healthy   ok                  </span><br><span class="line">etcd-0               Healthy   {<span class="string">"health"</span>:<span class="string">"true"</span>}</span><br></pre></td></tr></tbody></table></figure><h3 id="2-7-其它问题"><a href="#2-7-其它问题" class="headerlink" title="2.7 其它问题"></a>2.7 其它问题</h3><p><strong>问题：</strong>如果node节点kubelet报错：<code>Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady</code><br><strong>解决：</strong>将master节点的容器网络配置拷贝到node节点即可 /etc/cni/net.d/*</p><p><strong>问题：</strong>如果calico node节点活跃pod为0/1是因为calico-node容器获取到了错误的node节点IP</p><p><strong>解决：</strong>修改calico.yaml在calico-node中添加以下参数</p><figure class="highlight plain"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">- name: IP_AUTODETECTION_METHOD</span><br><span class="line">  value: "interface=ens33"</span><br></pre></td></tr></tbody></table></figure><h2 id="四、k8s高可用集群部署"><a href="#四、k8s高可用集群部署" class="headerlink" title="四、k8s高可用集群部署"></a>四、k8s高可用集群部署</h2><p>k8s高可用集群环境规划，需要准备一个给高可用服务的虚拟IP</p><table><thead><tr><th>主机名</th><th>IP地址</th><th>节点作用</th><th>k8s 相关组件</th><th>高可用组件</th></tr></thead><tbody><tr><td>k8s-master1</td><td>192.168.223.140</td><td>k8s-master</td><td>kubeadmin，kube-apiserver，kube-controller-manager，kube-scheduler，etcd，kube-proxy，kubelet</td><td>Haproxy，Keepalived</td></tr><tr><td>k8s-master2</td><td>192.168.223.144</td><td>k8s-master</td><td>kubeadmin，kube-apiserver，kube-controller-manager，kube-scheduler，etcd，kube-proxy，kubelet</td><td>Haproxy，Keepalived</td></tr><tr><td>k8s-master3</td><td>192.168.223.145</td><td>k8s-master</td><td>kubeadmin，kube-apiserver，kube-controller-manager，kube-scheduler，etcd，kube-proxy，kubelet</td><td>Haproxy，Keepalived</td></tr><tr><td>k8s-node1</td><td>192.168.223.142</td><td>k8s-node1</td><td>kubeadmin，kube-proxy，kubelet</td><td>-</td></tr></tbody></table><blockquote><p>系统初始化配置，按照<strong>一、系统初始化配置</strong> 进行配置<br>安装docker，按照<strong>二、安装docker</strong> 进行配置</p></blockquote><h3 id="4-1-安装kubeadm，kubelet和kubectl"><a href="#4-1-安装kubeadm，kubelet和kubectl" class="headerlink" title="4.1 安装kubeadm，kubelet和kubectl"></a>4.1 安装kubeadm，kubelet和kubectl</h3><p>3个master节点分别安装kubeadm，kubelet和kubectl</p><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># yum install -y kubelet-1.20.0 kubeadm-1.20.0 kubectl-1.20.0</span></span><br><span class="line"><span class="comment"># systemctl enable kubelet</span></span><br></pre></td></tr></tbody></table></figure><h3 id="4-2-部署etcd集群"><a href="#4-2-部署etcd集群" class="headerlink" title="4.2 部署etcd集群"></a>4.2 部署etcd集群</h3><p><strong>cfssl下载</strong> (选一台master 执行)</p><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[root@k8s-master1 ~]<span class="comment"># wget https://pkg.cfssl.org/R1.2/cfssl_linux-amd64 -O /usr/bin/cfssl</span></span><br><span class="line">[root@k8s-master1 ~]<span class="comment"># wget https://pkg.cfssl.org/R1.2/cfssljson_linux-amd64 -O    /usr/bin/cfssljson</span></span><br><span class="line">[root@k8s-master1 ~]<span class="comment"># chmod +x /usr/bin/cfssl /usr/bin/cfssljson</span></span><br></pre></td></tr></tbody></table></figure><p><strong>生成etcd CA、etcd证书</strong> （证书目录 在 /etc/etcd/ssl 下） （注意替换 -hostname= 里面IP地址 为所有masterIP地址）</p><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">[root@k8s-master1 ~]<span class="comment"># mkdir -p /etc/etcd/ssl &amp;&amp; cd /etc/etcd/ssl</span></span><br><span class="line">[root@k8s-master1 ssl]<span class="comment"># cat &gt; ca-config.json &lt;&lt;EOF</span></span><br><span class="line">{<span class="string">"signing"</span>:{<span class="string">"default"</span>:{<span class="string">"expiry"</span>:<span class="string">"87600h"</span>},<span class="string">"profiles"</span>:{<span class="string">"kubernetes"</span>:{<span class="string">"usages"</span>:[<span class="string">"signing"</span>,<span class="string">"key encipherment"</span>,<span class="string">"server auth"</span>,<span class="string">"client auth"</span>],<span class="string">"expiry"</span>:<span class="string">"87600h"</span>}}}}</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line">[root@k8s-master1 ssl]<span class="comment"># cat &gt; etcd-ca-csr.json &lt;&lt;EOF </span></span><br><span class="line">{<span class="string">"CN"</span>:<span class="string">"etcd"</span>,<span class="string">"key"</span>:{<span class="string">"algo"</span>:<span class="string">"rsa"</span>,<span class="string">"size"</span>:2048},<span class="string">"names"</span>:[{<span class="string">"C"</span>:<span class="string">"CN"</span>,<span class="string">"ST"</span>:<span class="string">"BeiJing"</span>,<span class="string">"L"</span>:<span class="string">"BeiJing"</span>,<span class="string">"O"</span>:<span class="string">"etcd"</span>,<span class="string">"OU"</span>:<span class="string">"etcd"</span>}]}</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line">[root@k8s-master1 ssl]<span class="comment"># cfssl gencert -initca etcd-ca-csr.json | cfssljson -bare etcd-ca</span></span><br><span class="line">[root@k8s-master1 ssl]<span class="comment"># cfssl gencert -ca=etcd-ca.pem -ca-key=etcd-ca-key.pem -config=ca-config.json -hostname=127.0.0.1,192.168.223.140,192.168.223.144,192.168.223.145 -profile=kubernetes etcd-ca-csr.json | cfssljson -bare etcd</span></span><br><span class="line"></span><br><span class="line">[root@k8s-master1 ssl]<span class="comment"># rm -rf *.json *.csr</span></span><br></pre></td></tr></tbody></table></figure><p>将/etc/etcd/ssl 目录下所有文件拷贝到 剩余master 节点 相同目录下</p><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@k8s-master1 ssl]<span class="comment"># scp /etc/etcd/ssl/* k8s-master2:/etc/etcd/ssl/</span></span><br><span class="line">[root@k8s-master1 ssl]<span class="comment"># scp /etc/etcd/ssl/* k8s-master3:/etc/etcd/ssl/</span></span><br></pre></td></tr></tbody></table></figure><p><strong>ETCD下载</strong> (所有master节点执行)</p><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># wget https://github.com/etcd-io/etcd/releases/download/v3.3.12/etcd-v3.3.12-linux-amd64.tar.gz</span></span><br><span class="line"><span class="comment"># tar zxvf etcd-v3.3.12-linux-amd64.tar.gz &amp;&amp; cd etcd-v3.3.12-linux-amd64</span></span><br><span class="line"><span class="comment"># cp etcd* /usr/bin/</span></span><br></pre></td></tr></tbody></table></figure><p><strong>添加etcd服务</strong> (所有master节点执行) (注意替换 IP地址 192.168 为本机IP，ETCD_NAME 改名)</p><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># cat &gt; /etc/etcd/config &lt;&lt; EOF</span></span><br><span class="line"><span class="comment">#[Member]</span></span><br><span class="line">ETCD_NAME=<span class="string">"etcd01"</span></span><br><span class="line">ETCD_DATA_DIR=<span class="string">"/var/lib/etcd/default.etcd"</span></span><br><span class="line">ETCD_LISTEN_PEER_URLS=<span class="string">"https://192.168.223.140:2380"</span></span><br><span class="line">ETCD_LISTEN_CLIENT_URLS=<span class="string">"https://192.168.223.140:2379"</span></span><br><span class="line"><span class="comment">#[Clustering]</span></span><br><span class="line">ETCD_INITIAL_ADVERTISE_PEER_URLS=<span class="string">"https://192.168.223.140:2380"</span></span><br><span class="line">ETCD_ADVERTISE_CLIENT_URLS=<span class="string">"https://192.168.223.140:2379"</span></span><br><span class="line">ETCD_INITIAL_CLUSTER=<span class="string">"etcd01=https://192.168.223.140:2380,etcd02=https://192.168.223.144:2380,etcd03=https://192.168.223.145:2380"</span></span><br><span class="line">ETCD_INITIAL_CLUSTER_TOKEN=<span class="string">"etcd-cluster"</span></span><br><span class="line">ETCD_INITIAL_CLUSTER_STATE=<span class="string">"new"</span></span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line"><span class="comment"># vim /usr/lib/systemd/system/etcd.service</span></span><br><span class="line">[Unit]</span><br><span class="line">Description=Etcd Server</span><br><span class="line">After=neCNork.target</span><br><span class="line">After=network-online.target</span><br><span class="line">Wants=network-online.target</span><br><span class="line">[Service]</span><br><span class="line">Type=notify</span><br><span class="line">EnvironmentFile=/etc/etcd/config</span><br><span class="line">ExecStart=/usr/bin/etcd \</span><br><span class="line">--name=<span class="variable">${ETCD_NAME}</span> \</span><br><span class="line">--data-dir=<span class="variable">${ETCD_DATA_DIR}</span> \</span><br><span class="line">--listen-peer-urls=<span class="variable">${ETCD_LISTEN_PEER_URLS}</span> \</span><br><span class="line">--listen-client-urls=<span class="variable">${ETCD_LISTEN_CLIENT_URLS}</span>,http://127.0.0.1:2379 \</span><br><span class="line">--advertise-client-urls=<span class="variable">${ETCD_ADVERTISE_CLIENT_URLS}</span> \</span><br><span class="line">--initial-advertise-peer-urls=<span class="variable">${ETCD_INITIAL_ADVERTISE_PEER_URLS}</span> \</span><br><span class="line">--initial-cluster=<span class="variable">${ETCD_INITIAL_CLUSTER}</span> \</span><br><span class="line">--initial-cluster-token=<span class="variable">${ETCD_INITIAL_CLUSTER_TOKEN}</span> \</span><br><span class="line">--initial-cluster-state=new \</span><br><span class="line">--cert-file=/etc/etcd/ssl/etcd.pem \</span><br><span class="line">--key-file=/etc/etcd/ssl/etcd-key.pem \</span><br><span class="line">--peer-cert-file=/etc/etcd/ssl/etcd.pem \</span><br><span class="line">--peer-key-file=/etc/etcd/ssl/etcd-key.pem \</span><br><span class="line">--trusted-ca-file=/etc/etcd/ssl/etcd-ca.pem \</span><br><span class="line">--peer-trusted-ca-file=/etc/etcd/ssl/etcd-ca.pem</span><br><span class="line">Restart=on-failure</span><br><span class="line">LimitNOFILE=65536</span><br><span class="line">[Install]</span><br><span class="line">WantedBy=multi-user.target</span><br></pre></td></tr></tbody></table></figure><p><strong>启动3台master上的etcd</strong>，查看etcd集群状态</p><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">##启动ETCD </span></span><br><span class="line"><span class="comment"># systemctl enable --now etcd</span></span><br><span class="line"></span><br><span class="line"><span class="comment">##检查etcd集群状态</span></span><br><span class="line"><span class="comment">#  ETCDCTL_API=3 etcdctl --cacert=/etc/etcd/ssl/etcd-ca.pem --cert=/etc/etcd/ssl/etcd.pem --key=/etc/etcd/ssl/etcd-key.pem --endpoints="https://192.168.223.140:2379,https://192.168.223.144:2379,https://192.168.223.145:2379" member list</span></span><br><span class="line">+------------------+---------+--------+------------------------------+------------------------------+</span><br><span class="line">|        ID        | STATUS  |  NAME  |          PEER ADDRS          |         CLIENT ADDRS         |</span><br><span class="line">+------------------+---------+--------+------------------------------+------------------------------+</span><br><span class="line">|  181017bd7f7e566 | started | etcd02 | https://192.168.223.144:2380 | https://192.168.223.144:2379 |</span><br><span class="line">|  f67525124b345fa | started | etcd03 | https://192.168.223.145:2380 | https://192.168.223.145:2379 |</span><br><span class="line">| 3e9b0ead5c1d30ac | started | etcd01 | https://192.168.223.140:2380 | https://192.168.223.140:2379 |</span><br><span class="line">+------------------+---------+--------+------------------------------+------------------------------+</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># ETCDCTL_API=3 etcdctl --cacert=/etc/etcd/ssl/etcd-ca.pem --cert=/etc/etcd/ssl/etcd.pem --key=/etc/etcd/ssl/etcd-key.pem --endpoints="https://192.168.223.140:2379,https://192.168.223.144:2379,https://192.168.223.145:2379" --write-out=table endpoint status</span></span><br><span class="line">+------------------------------+------------------+---------+---------+-----------+-----------+------------+</span><br><span class="line">|           ENDPOINT           |        ID        | VERSION | DB SIZE | IS LEADER | RAFT TERM | RAFT INDEX |</span><br><span class="line">+------------------------------+------------------+---------+---------+-----------+-----------+------------+</span><br><span class="line">| https://192.168.223.140:2379 | 3e9b0ead5c1d30ac |  3.3.12 |   20 kB |      <span class="literal">true</span> |        22 |         18 |</span><br><span class="line">| https://192.168.223.144:2379 |  181017bd7f7e566 |  3.3.12 |   20 kB |     <span class="literal">false</span> |        22 |         18 |</span><br><span class="line">| https://192.168.223.145:2379 |  f67525124b345fa |  3.3.12 |   20 kB |     <span class="literal">false</span> |        22 |         18 |</span><br><span class="line">+------------------------------+------------------+---------+---------+-----------+-----------+------------+</span><br></pre></td></tr></tbody></table></figure><p>到此部署完了etcd集群，使用kubeadm部署etcd集群可参考<a href="https://kubernetes.io/zh-cn/docs/setup/production-environment/tools/kubeadm/setup-ha-etcd-with-kubeadm/" target="_blank" rel="noopener">官网</a></p><h3 id="4-3-配置apiserver-高可用VIP"><a href="#4-3-配置apiserver-高可用VIP" class="headerlink" title="4.3 配置apiserver 高可用VIP"></a>4.3 配置apiserver 高可用VIP</h3><p>高可用我们采用官方推荐的<code>HAproxy + Keepalived</code>，<code>HAproxy</code>和<code>Keepalived</code>以守护进程的方式在所有<code>Master</code>节点部署。</p><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># yum install -y keepalived haproxy</span></span><br><span class="line"></span><br><span class="line"><span class="comment">##如果要提前测试VIP能否正常使用，可以使用命令</span></span><br><span class="line"><span class="comment"># ip addr add 192.168.223.150/24 dev eno16777736</span></span><br><span class="line"><span class="comment">##测试完后记得卸载IP</span></span><br><span class="line"><span class="comment"># ip addr del 192.168.223.150 dev eno16777736</span></span><br></pre></td></tr></tbody></table></figure><p><strong>配置 Haproxy 服务</strong></p><p>所有<code>master</code>节点的<code>haproxy</code>配置相同，haproxy的配置文件是<code>/etc/haproxy/haproxy.cfg</code>。<code>master1</code>节点配置完成之后再分发给<code>master2、master3</code>两个节点。</p><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line">[root@k8s-master1 ~]<span class="comment"># cat /etc/haproxy/haproxy.cfg</span></span><br><span class="line">global</span><br><span class="line">  maxconn  2000</span><br><span class="line">  <span class="built_in">ulimit</span>-n  16384</span><br><span class="line">  <span class="built_in">log</span>  127.0.0.1 local0 err</span><br><span class="line">  stats timeout 30s</span><br><span class="line"></span><br><span class="line">defaults</span><br><span class="line">  <span class="built_in">log</span> global</span><br><span class="line">  mode  http</span><br><span class="line">  option  httplog</span><br><span class="line">  timeout connect 5000</span><br><span class="line">  timeout client  50000</span><br><span class="line">  timeout server  50000</span><br><span class="line">  timeout http-request 15s</span><br><span class="line">  timeout http-keep-alive 15s</span><br><span class="line"></span><br><span class="line">frontend monitor-in</span><br><span class="line">  <span class="built_in">bind</span> *:33305</span><br><span class="line">  mode http</span><br><span class="line">  option httplog</span><br><span class="line">  monitor-uri /monitor</span><br><span class="line"></span><br><span class="line">listen stats</span><br><span class="line">  <span class="built_in">bind</span>    *:8006</span><br><span class="line">  mode    http</span><br><span class="line">  stats   <span class="built_in">enable</span></span><br><span class="line">  stats   hide-version</span><br><span class="line">  stats   uri       /stats</span><br><span class="line">  stats   refresh   30s</span><br><span class="line">  stats   realm     Haproxy\ Statistics</span><br><span class="line">  stats   auth      admin:admin</span><br><span class="line"></span><br><span class="line">frontend k8s-master</span><br><span class="line">  <span class="built_in">bind</span> 0.0.0.0:8443</span><br><span class="line">  <span class="built_in">bind</span> 127.0.0.1:8443</span><br><span class="line">  mode tcp</span><br><span class="line">  option tcplog</span><br><span class="line">  tcp-request inspect-delay 5s</span><br><span class="line">  default_backend k8s-master</span><br><span class="line"></span><br><span class="line">backend k8s-master</span><br><span class="line">  mode tcp</span><br><span class="line">  option tcplog</span><br><span class="line">  option tcp-check</span><br><span class="line">  balance roundrobin</span><br><span class="line">  default-server inter 10s downinter 5s rise 2 fall 2 slowstart 60s maxconn 250 maxqueue 256 weight 100</span><br><span class="line">  server master1 k8s-master1:6443  check inter 2000 fall 2 rise 2 weight 100</span><br><span class="line">  server master2 k8s-master2:6443  check inter 2000 fall 2 rise 2 weight 100</span><br><span class="line">  server master3 k8s-master3:6443  check inter 2000 fall 2 rise 2 weight 100</span><br></pre></td></tr></tbody></table></figure><p>注意修改：server master1 k8s-master1:6443，中的<code>k8s-master1</code>，换成master节点的IP或配置的hosts解析名称</p><p><strong>配置Keepalived服务</strong><br>keepalived中使用track_script机制来配置脚本进行探测kubernetes的master节点是否宕机，并以此切换节点实现高可用。</p><p>master1节点的keepalived配置文件如下所示，配置文件所在的位置/etc/keepalived/keepalived.cfg</p><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">[root@k8s-master1 ~]<span class="comment"># cat /etc/keepalived/keepalived.conf </span></span><br><span class="line">! Configuration File <span class="keyword">for</span> keepalived</span><br><span class="line">global_defs {</span><br><span class="line">    router_id LVS_DEVEL</span><br><span class="line">}</span><br><span class="line">vrrp_script chk_kubernetes {</span><br><span class="line">    script <span class="string">"/etc/keepalived/check_kubernetes.sh"</span></span><br><span class="line">    interval 2</span><br><span class="line">    weight -5</span><br><span class="line">    fall 3  </span><br><span class="line">    rise 2</span><br><span class="line">}</span><br><span class="line">vrrp_instance VI_1 {</span><br><span class="line">    state MASTER</span><br><span class="line">    interface eno16777736</span><br><span class="line">    mcast_src_ip 192.168.223.140</span><br><span class="line">    virtual_router_id 51</span><br><span class="line">    priority 100</span><br><span class="line">    advert_int 2</span><br><span class="line">    authentication {</span><br><span class="line">        auth_type PASS</span><br><span class="line">        auth_pass K8SHA_KA_AUTH</span><br><span class="line">    }</span><br><span class="line">    virtual_ipaddress {</span><br><span class="line">        192.168.223.150</span><br><span class="line">    }</span><br><span class="line"><span class="comment">#    track_script {  ##这里注释是因为haproxy代理的6443端口还没启起来，后面部署了kube-apiserver再启用这个配置</span></span><br><span class="line"><span class="comment">#       chk_kubernetes</span></span><br><span class="line"><span class="comment">#    }</span></span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure><p><strong>注：</strong>需要注意几点（记得修改）：</p><blockquote><p>interface：网卡名称<br>mcast_src_ip：配置多播源地址，此地址是当前主机的ip地址。<br>priority：keepalived根据此项参数的大小仲裁master节点。我们这里让master节点为kubernetes提供服务，其他两个节点暂时为备用节点。因此master1节点设置为100，master2节点设置为99，master3节点设置为98。<br>state：我们将master1节点的state字段设置为MASTER，其他两个节点字段修改为BACKUP。<br>上面的集群检查功能是关闭的，等到集群建立完成后再开启。<br>virtual_ipaddress：高可用虚拟IP</p></blockquote><p><strong>注：</strong>根据上面的注意事项配置master2、master3节点的keepalived服务。</p><p><strong>配置健康检测脚本</strong></p><p>这里将健康检测脚本放置在<code>/etc/keepalived</code>目录下，<code>check_kubernetes.sh</code>检测脚本如下</p><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">[root@master1 keepalived]<span class="comment"># cat check_kubernetes.sh </span></span><br><span class="line"><span class="meta">#!/bin/bash</span></span><br><span class="line"><span class="keyword">function</span> <span class="function"><span class="title">check_kubernetes</span></span>() {</span><br><span class="line"> <span class="keyword">for</span> ((i=0;i&lt;5;i++));<span class="keyword">do</span></span><br><span class="line">  apiserver_pid_id=$(pgrep kube-apiserver)</span><br><span class="line">  <span class="keyword">if</span> [[ ! -z <span class="variable">$apiserver_pid_id</span> ]];<span class="keyword">then</span></span><br><span class="line">   <span class="built_in">return</span></span><br><span class="line">  <span class="keyword">else</span></span><br><span class="line">   sleep 2</span><br><span class="line">  <span class="keyword">fi</span></span><br><span class="line">  apiserver_pid_id=0</span><br><span class="line"> <span class="keyword">done</span></span><br><span class="line">}</span><br><span class="line"></span><br><span class="line"><span class="comment"># 1:running  0:stopped</span></span><br><span class="line">check_kubernetes</span><br><span class="line"><span class="keyword">if</span> [[ <span class="variable">$apiserver_pid_id</span> -eq 0 ]];<span class="keyword">then</span></span><br><span class="line"> /usr/bin/systemctl stop keepalived</span><br><span class="line"> <span class="built_in">exit</span> 1</span><br><span class="line"><span class="keyword">else</span></span><br><span class="line"> <span class="built_in">exit</span> 0</span><br><span class="line"><span class="keyword">fi</span></span><br></pre></td></tr></tbody></table></figure><p><strong>启动<code>Keeplived</code>和<code>Haproxy</code>服务</strong></p><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[root@k8s-master1 ~]<span class="comment"># systemctl enable --now keepalived haproxy</span></span><br><span class="line"></span><br><span class="line"><span class="comment">##检查一下服务状态</span></span><br><span class="line">[root@k8s-master1 ~]<span class="comment"># systemctl status keepalived haproxy</span></span><br></pre></td></tr></tbody></table></figure><h3 id="4-4-初始化k8s-集群"><a href="#4-4-初始化k8s-集群" class="headerlink" title="4.4 初始化k8s 集群"></a>4.4 初始化k8s 集群</h3><p>初始化kubeadm 使用的文件，修改以下几项参数</p><figure class="highlight yaml"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">[root@k8s-master1</span> <span class="string">~]#</span> <span class="string">kubeadm</span> <span class="string">config</span> <span class="string">print</span> <span class="string">init-defaults</span> <span class="string">&gt; kubeadm-config.yaml</span></span><br><span class="line"><span class="string">[root@k8s-master1 ~]# vim kubeadm-config.yaml</span></span><br><span class="line"><span class="string"></span><span class="attr">apiVersion:</span> <span class="string">kubeadm.k8s.io/v1beta2</span></span><br><span class="line"><span class="attr">bootstrapTokens:</span></span><br><span class="line"><span class="attr">- groups:</span></span><br><span class="line"><span class="attr">  - system:</span><span class="attr">bootstrappers:kubeadm:default-node-token</span></span><br><span class="line"><span class="attr">  token:</span> <span class="string">abcdef.0123456789abcdef</span></span><br><span class="line"><span class="attr">  ttl:</span> <span class="number">24</span><span class="string">h0m0s</span></span><br><span class="line"><span class="attr">  usages:</span></span><br><span class="line"><span class="bullet">  -</span> <span class="string">signing</span></span><br><span class="line"><span class="bullet">  -</span> <span class="string">authentication</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">InitConfiguration</span></span><br><span class="line"><span class="attr">localAPIEndpoint:</span></span><br><span class="line"><span class="attr">  advertiseAddress:</span> <span class="number">192.168</span><span class="number">.223</span><span class="number">.150</span>  <span class="comment">#VIP地址</span></span><br><span class="line"><span class="attr">  bindPort:</span> <span class="number">6443</span></span><br><span class="line"><span class="attr">nodeRegistration:</span></span><br><span class="line"><span class="attr">  criSocket:</span> <span class="string">/var/run/dockershim.sock</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">k8s-master1</span></span><br><span class="line"><span class="attr">  taints:</span></span><br><span class="line"><span class="attr">  - effect:</span> <span class="string">NoSchedule</span></span><br><span class="line"><span class="attr">    key:</span> <span class="string">node-role.kubernetes.io/master</span></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="attr">apiServer:</span></span><br><span class="line"><span class="attr">  certSANs:</span></span><br><span class="line"><span class="bullet">  -</span> <span class="string">"192.168.223.150"</span>         <span class="comment">#VIP地址</span></span><br><span class="line"><span class="attr">  timeoutForControlPlane:</span> <span class="number">4</span><span class="string">m0s</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">kubeadm.k8s.io/v1beta2</span></span><br><span class="line"><span class="attr">certificatesDir:</span> <span class="string">/etc/kubernetes/pki</span></span><br><span class="line"><span class="attr">clusterName:</span> <span class="string">kubernetes</span></span><br><span class="line"><span class="attr">controllerManager:</span> <span class="string">{}</span></span><br><span class="line"><span class="attr">dns:</span></span><br><span class="line"><span class="attr">  type:</span> <span class="string">CoreDNS</span></span><br><span class="line"><span class="attr">etcd:</span></span><br><span class="line"><span class="attr">  local:</span></span><br><span class="line"><span class="attr">    dataDir:</span> <span class="string">/var/lib/etcd</span></span><br><span class="line"><span class="attr">imageRepository:</span> <span class="string">registry.cn-hangzhou.aliyuncs.com/google_containers</span>  <span class="comment">#阿里云的镜像站点</span></span><br><span class="line"><span class="attr">controlPlaneEndpoint:</span> <span class="string">"192.168.223.150:8443"</span>   <span class="comment">#VIP的地址和端口(haproxy监控端口)</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">ClusterConfiguration</span></span><br><span class="line"><span class="attr">kubernetesVersion:</span> <span class="string">v1.20.0</span>      <span class="comment">#k8s版本号</span></span><br><span class="line"><span class="attr">networking:</span></span><br><span class="line"><span class="attr">  dnsDomain:</span> <span class="string">cluster.local</span></span><br><span class="line"><span class="attr">  serviceSubnet:</span> <span class="number">10.96</span><span class="number">.0</span><span class="number">.0</span><span class="string">/12</span>   <span class="comment">#选择默认即可，当然也可以自定义CIDR</span></span><br><span class="line"><span class="attr">  podSubnet:</span> <span class="number">172.0</span><span class="number">.0</span><span class="number">.0</span><span class="string">/16</span>       <span class="comment">#添加pod网段</span></span><br><span class="line"><span class="attr">scheduler:</span> <span class="string">{}</span></span><br></pre></td></tr></tbody></table></figure><p><strong>注意：</strong>上面的advertiseAddress字段的值，这个值并非当前主机的网卡地址，而是高可用集群的VIP的地址。<br><strong>注意：</strong>上面的controlPlaneEndpoint这里填写的是VIP的地址，而端口则是haproxy服务的8443端口，也就是我们在haproxy里面配置的这段信息</p><figure class="highlight plain"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">frontend k8s-master</span><br><span class="line">  bind 0.0.0.0:8443</span><br><span class="line">  bind 127.0.0.1:8443</span><br><span class="line">  mode tcp</span><br></pre></td></tr></tbody></table></figure><p>这一段里面的8443端，如果你自定义了其他端口，这里请记得修改<code>controlPlaneEndpoint</code>里面的端口。</p><p><strong>提前拉取镜像</strong></p><p>如果直接采用kubeadm init来初始化，中间会有系统自动拉取镜像的这一步骤，这是比较慢的，我建议分开来做，所以这里就先提前拉取镜像。其他两个master节点在初始化之前也尽量先把镜像拉取下来，这样子减少初始化时间（别忘了将初始化文件拷贝到其余master节点）。</p><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[root@k8s-master1 ~]<span class="comment"># kubeadm config images pull --config kubeadm-config.yaml</span></span><br><span class="line">[root@k8s-master2 ~]<span class="comment"># kubeadm config images pull --config kubeadm-config.yaml</span></span><br><span class="line">[root@k8s-master3 ~]<span class="comment"># kubeadm config images pull --config kubeadm-config.yaml</span></span><br></pre></td></tr></tbody></table></figure><p><strong>初始化<code>kubenetes</code>的<code>master1</code>节点</strong></p><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line">[root@k8s-master1 ~]<span class="comment"># kubeadm init --config=kubeadm-config.yaml --upload-certs</span></span><br><span class="line">执行成功结果……</span><br><span class="line">[addons] Applied essential addon: kube-proxy</span><br><span class="line"></span><br><span class="line">Your Kubernetes control-plane has initialized successfully!</span><br><span class="line"></span><br><span class="line">To start using your cluster, you need to run the following as a regular user:</span><br><span class="line"></span><br><span class="line">  mkdir -p <span class="variable">$HOME</span>/.kube</span><br><span class="line">  sudo cp -i /etc/kubernetes/admin.conf <span class="variable">$HOME</span>/.kube/config</span><br><span class="line">  sudo chown $(id -u):$(id -g) <span class="variable">$HOME</span>/.kube/config</span><br><span class="line"></span><br><span class="line">Alternatively, <span class="keyword">if</span> you are the root user, you can run:</span><br><span class="line"></span><br><span class="line">  <span class="built_in">export</span> KUBECONFIG=/etc/kubernetes/admin.conf</span><br><span class="line"></span><br><span class="line">You should now deploy a pod network to the cluster.</span><br><span class="line">Run <span class="string">"kubectl apply -f [podnetwork].yaml"</span> with one of the options listed at:</span><br><span class="line">  https://kubernetes.io/docs/concepts/cluster-administration/addons/</span><br><span class="line"></span><br><span class="line">You can now join any number of the control-plane node running the following <span class="built_in">command</span> on each as root:</span><br><span class="line"></span><br><span class="line">  kubeadm join 192.168.223.150:8443 --token abcdef.0123456789abcdef \</span><br><span class="line">    --discovery-token-ca-cert-hash sha256:c88fcaa53c0dfb1940a1fde4854be3a76466a7de7375a13894571ca361b2b1a8 \</span><br><span class="line">    --control-plane --certificate-key 0a345539c4a91353017c0aa826dd8b3477f20bd158e052915dda4718eeeb159f</span><br><span class="line"></span><br><span class="line">Please note that the certificate-key gives access to cluster sensitive data, keep it secret!</span><br><span class="line">As a safeguard, uploaded-certs will be deleted <span class="keyword">in</span> two hours; If necessary, you can use</span><br><span class="line"><span class="string">"kubeadm init phase upload-certs --upload-certs"</span> to reload certs afterward.</span><br><span class="line"></span><br><span class="line">Then you can join any number of worker nodes by running the following on each as root:</span><br><span class="line"></span><br><span class="line">kubeadm join 192.168.223.150:8443 --token abcdef.0123456789abcdef \</span><br><span class="line">    --discovery-token-ca-cert-hash sha256:c88fcaa53c0dfb1940a1fde4854be3a76466a7de7375a13894571ca361b2b1a8</span><br></pre></td></tr></tbody></table></figure><p><strong>添加kubectl config</strong></p><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">[root@k8s-master1 ~]<span class="comment"># mkdir -p $HOME/.kube</span></span><br><span class="line">[root@k8s-master1 ~]<span class="comment"># sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config</span></span><br><span class="line">[root@k8s-master1 ~]<span class="comment"># sudo chown $(id -u):$(id -g) $HOME/.kube/config</span></span><br><span class="line"></span><br><span class="line">[root@k8s-master1 ~]<span class="comment"># kubectl get no</span></span><br><span class="line">NAME          STATUS     ROLES                  AGE   VERSION</span><br><span class="line">k8s-master1   NotReady   control-plane,master   97s   v1.20.0</span><br></pre></td></tr></tbody></table></figure><h3 id="4-5-启用keepalived-检测功能"><a href="#4-5-启用keepalived-检测功能" class="headerlink" title="4.5 启用keepalived 检测功能"></a>4.5 启用keepalived 检测功能</h3><p>k8s集群初始化后kube-apiserver服务已运行，现在可以将3个master 节点<strong>keepalived</strong>配置文件的 <code>track_script</code> 字段取消注释，并重启keepalived 服务</p><h3 id="4-6-Master-节点加入集群"><a href="#4-6-Master-节点加入集群" class="headerlink" title="4.6 Master 节点加入集群"></a>4.6 Master 节点加入集群</h3><p>根据提示<strong>添加其他master 节点</strong> （master2、master3 上执行）</p><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">[root@k8s-master2 ~]<span class="comment"># kubeadm join 192.168.223.150:8443 --token abcdef.0123456789abcdef \</span></span><br><span class="line">    --discovery-token-ca-cert-hash sha256:c88fcaa53c0dfb1940a1fde4854be3a76466a7de7375a13894571ca361b2b1a8 \</span><br><span class="line">    --control-plane --certificate-key 0a345539c4a91353017c0aa826dd8b3477f20bd158e052915dda4718eeeb159f</span><br><span class="line">    </span><br><span class="line">[root@k8s-master3 ~]<span class="comment"># kubeadm join 192.168.223.150:8443 --token abcdef.0123456789abcdef \</span></span><br><span class="line">    --discovery-token-ca-cert-hash sha256:c88fcaa53c0dfb1940a1fde4854be3a76466a7de7375a13894571ca361b2b1a8 \</span><br><span class="line">    --control-plane --certificate-key 0a345539c4a91353017c0aa826dd8b3477f20bd158e052915dda4718eeeb159f</span><br></pre></td></tr></tbody></table></figure><p>如果节点在加入集群时报错<code>[ERROR Port-10250]: Port 10250 is in use</code> 在报错的节点执行<code>kubeadm reset</code></p><h3 id="4-8-node-节点加入集群"><a href="#4-8-node-节点加入集群" class="headerlink" title="4.8 node 节点加入集群"></a>4.8 node 节点加入集群</h3><p>根据提示添加 work 节点</p><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">[root@k8s-node1 ~]<span class="comment"># kubeadm join 192.168.223.150:8443 --token abcdef.0123456789abcdef \</span></span><br><span class="line">    --discovery-token-ca-cert-hash sha256:c88fcaa53c0dfb1940a1fde4854be3a76466a7de7375a13894571ca361b2b1a8</span><br><span class="line"></span><br><span class="line">[root@k8s-master1 ~]<span class="comment"># kubectl get no</span></span><br><span class="line">NAME          STATUS     ROLES                  AGE   VERSION</span><br><span class="line">k8s-master1   NotReady   control-plane,master   39m   v1.20.0</span><br><span class="line">k8s-master2   NotReady   control-plane,master   10m   v1.20.0</span><br><span class="line">k8s-master3   NotReady   control-plane,master   10m   v1.20.0</span><br><span class="line">k8s-node1     NotReady   &lt;none&gt;                 11s   v1.20.0</span><br></pre></td></tr></tbody></table></figure><p>到此高可用k8s集群部署基本完成，后续部署网络插件根据 <strong>2.3 部署网络插件</strong> 进行操作即可</p><h2 id="五、集群-token-过期处理"><a href="#五、集群-token-过期处理" class="headerlink" title="五、集群 token 过期处理"></a>五、集群 token 过期处理</h2><p>默认token有效期为24小时，当过期之后，该token就不可用了。这时就需要重新创建token，可以直接使用命令快捷生成</p><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@k8s-master ~]<span class="comment"># kubeadm token create --print-join-command</span></span><br><span class="line">kubeadm join 192.168.223.140:6443 --token hpgvxz.q1iso7sfyoipqyp7     --discovery-token-ca-cert-hash sha256:1f06697abdb74cdfc9601d32a45fcf636084bc7ba3de7180dacf97f1403a98c2</span><br></pre></td></tr></tbody></table></figure><p>如果已运行的集群出现token过期，kubelet、kube-apiserver，kube-controller-manager等服务都报token过期相关的错误，重新生成token后重启k8s相关服务即可恢复集群</p><h2 id="六、卸载-flannel-网络插件"><a href="#六、卸载-flannel-网络插件" class="headerlink" title="六、卸载 flannel 网络插件"></a>六、卸载 flannel 网络插件</h2><p><strong>master节点删除flannel容器资源</strong></p><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@k8s-master ~]<span class="comment"># kubectl delete -f kube-flannel.yml</span></span><br></pre></td></tr></tbody></table></figure><p><strong>在所有节点清理flannel</strong>网络插件留下的文件（如果没有创建pod那么cni0网桥只有master存在，意味着只要服务器上有cni0和flannel.l就需要执行下面命令）</p><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">ifconfig cni0 down</span><br><span class="line">ip link delete cni0</span><br><span class="line">ifconfig flannel.1 down</span><br><span class="line">ip link delete flannel.1</span><br><span class="line">rm -rf /var/lib/cni/</span><br><span class="line">rm -f /etc/cni/net.d/*</span><br></pre></td></tr></tbody></table></figure><p>注意：如果有vteh设备的也要清理掉</p><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># ifconfig vethdc52a97e down</span></span><br><span class="line"><span class="comment"># ip link delete vethdc52a97e</span></span><br></pre></td></tr></tbody></table></figure><p><strong>清理完成后要重启kubelet</strong></p><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># systemctl restart kubelet</span></span><br></pre></td></tr></tbody></table></figure><h2 id="七、卸载-k8s-集群"><a href="#七、卸载-k8s-集群" class="headerlink" title="七、卸载 k8s 集群"></a>七、卸载 k8s 集群</h2><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># kubeadm reset -f</span></span><br></pre></td></tr></tbody></table></figure><p>卸载k8s服务</p><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># modprobe -r ipip</span></span><br></pre></td></tr></tbody></table></figure><p>#Linux modprobe命令用于自动处理可载入模块。</p><p>#-r或–remove 　模块闲置不用时，即自动卸载模块。</p><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># lsmod</span></span><br></pre></td></tr></tbody></table></figure><p>#lsmod 命令：用来显示文件、proc/modules的信息，也就是显示当前内核模块装载的模块。</p><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">sudo systemctl stop kubelet kube-proxy flanneld kube-apiserver kube-controller-manager kube-scheduler</span><br><span class="line"></span><br><span class="line">sudo rm -rf ~/.kube/</span><br><span class="line">sudo rm -rf /etc/kubernetes/</span><br><span class="line">sudo rm -rf /usr/bin/kube*</span><br><span class="line">sudo rm -rf /etc/cni</span><br><span class="line">sudo rm -rf /opt/cni</span><br><span class="line">sudo rm -rf /var/etcd</span><br><span class="line">sudo rm -rf /var/lib/etcd</span><br><span class="line">sudo rm -rf /var/lib/kubelet</span><br><span class="line">sudo rm -rf /var/run/Kubernetes</span><br><span class="line">sudo rm -rf /var/run/flannel/</span><br><span class="line">sudo rm -rf /etc/systemd/system/{etcd,kubelet,kube-apiserver,kube-controller-manager,kube-scheduler,flanneld}.service</span><br><span class="line"></span><br><span class="line">mount | grep <span class="string">'/var/lib/kubelet'</span>| awk <span class="string">'{print $3}'</span>|xargs sudo umount</span><br><span class="line">sudo rm -rf /root/<span class="built_in">local</span>/bin/{etcd,kubelet,kube-apiserver,kube-controller-manager,kube-scheduler,flanneld,mk-docker-opts.sh}</span><br><span class="line">sudo yum clean all</span><br><span class="line">yum remove -y kubelet kubeadm kubectl</span><br></pre></td></tr></tbody></table></figure><script>document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });</script></div><div><div><div style="text-align:center;color:#ccc;font-size:14px">-------------本文结束<i class="fa fa-paw"></i>感谢您的阅读-------------</div></div></div><div></div><footer class="post-footer"><div class="post-tags"><a href="/tags/kubernetes-kubeadm/" rel="tag"><i class="fa fa-tag"></i> kubernetes - kubeadm</a></div><div class="post-nav"><div class="post-nav-next post-nav-item"><a href="/2022/12/17/minio-shu-ju-qian-yi/" rel="next" title="Minio 数据迁移"><i class="fa fa-chevron-left"></i> Minio 数据迁移</a></div><span class="post-nav-divider"></span><div class="post-nav-prev post-nav-item"><a href="/2022/12/25/k8s-zhong-yun-xing-kafka/" rel="prev" title="K8s 中运行Kafka">K8s 中运行Kafka<i class="fa fa-chevron-right"></i></a></div></div></footer></div></article><div class="post-spread"><div class="jiathis_style"><span class="jiathis_txt">分享到：</span> <a class="jiathis_button_fav">收藏夹</a> <a class="jiathis_button_copy">复制网址</a> <a class="jiathis_button_email">邮件</a> <a class="jiathis_button_weixin">微信</a> <a class="jiathis_button_qzone">QQ空间</a> <a class="jiathis_button_tqq">腾讯微博</a> <a class="jiathis_button_douban">豆瓣</a> <a class="jiathis_button_share">一键分享</a> <a href="http://www.jiathis.com/share?uid=2140465" class="jiathis jiathis_txt jiathis_separator jtico jtico_jiathis" target="_blank">更多</a><a class="jiathis_counter_style"></a></div><script type="text/javascript">var jiathis_config={data_track_clickback:!0,summary:"",shortUrl:!1,hideMore:!1}</script><script type="text/javascript" src="http://v3.jiathis.com/code/jia.js?uid=" charset="utf-8"></script></div></div></div></div><div class="sidebar-toggle"><div class="sidebar-toggle-line-wrap"><span class="sidebar-toggle-line sidebar-toggle-line-first"></span><span class="sidebar-toggle-line sidebar-toggle-line-middle"></span><span class="sidebar-toggle-line sidebar-toggle-line-last"></span></div></div><aside id="sidebar" class="sidebar"><div id="sidebar-dimmer"></div><div class="sidebar-inner"><ul class="sidebar-nav motion-element"><li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">文章目录</li><li class="sidebar-nav-overview" data-target="site-overview-wrap">站点概览</li></ul><section class="site-overview-wrap sidebar-panel"><div class="site-overview"><div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person"><img class="site-author-image" itemprop="image" src="/images/chen.png" alt="Zhongzhou Chen"><p class="site-author-name" itemprop="name">Zhongzhou Chen</p><p class="site-description motion-element" itemprop="description"></p></div><nav class="site-state motion-element"><div class="site-state-item site-state-posts"><a href="/archives/%7C%7C%20archive"><span class="site-state-item-count">371</span> <span class="site-state-item-name">日志</span></a></div><div class="site-state-item site-state-categories"><a href="/categories/index.html"><span class="site-state-item-count">89</span> <span class="site-state-item-name">分类</span></a></div><div class="site-state-item site-state-tags"><a href="/tags/index.html"><span class="site-state-item-count">188</span> <span class="site-state-item-name">标签</span></a></div></nav><div class="feed-link motion-element"><a href="/atom.xml" rel="alternate"><i class="fa fa-rss"></i> RSS</a></div></div></section><section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active"><div class="post-toc"><div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#kubeadm部署k8s集群"><span class="nav-text">kubeadm部署k8s集群</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#一、系统初始化配置"><span class="nav-text">一、系统初始化配置</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#二、安装docker"><span class="nav-text">二、安装docker</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#三、kubeadm安装k8s集群"><span class="nav-text">三、kubeadm安装k8s集群</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#2-1-安装kubeadm，kubelet和kubectl"><span class="nav-text">2.1 安装kubeadm，kubelet和kubectl</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-2-初始化master节点"><span class="nav-text">2.2 初始化master节点</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-3-部署网络插件"><span class="nav-text">2.3 部署网络插件</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#2-3-1-部署网络插件-flannel"><span class="nav-text">2.3.1 部署网络插件 flannel</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#2-3-2-部署网络插件-calico"><span class="nav-text">2.3.2 部署网络插件 calico</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-4-node-节点加入集群"><span class="nav-text">2.4 node 节点加入集群</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-5-部署-nginx-测试"><span class="nav-text">2.5 部署 nginx 测试</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-6-组件-Unhealthy-问题"><span class="nav-text">2.6 组件 Unhealthy 问题</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-7-其它问题"><span class="nav-text">2.7 其它问题</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#四、k8s高可用集群部署"><span class="nav-text">四、k8s高可用集群部署</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#4-1-安装kubeadm，kubelet和kubectl"><span class="nav-text">4.1 安装kubeadm，kubelet和kubectl</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#4-2-部署etcd集群"><span class="nav-text">4.2 部署etcd集群</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#4-3-配置apiserver-高可用VIP"><span class="nav-text">4.3 配置apiserver 高可用VIP</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#4-4-初始化k8s-集群"><span class="nav-text">4.4 初始化k8s 集群</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#4-5-启用keepalived-检测功能"><span class="nav-text">4.5 启用keepalived 检测功能</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#4-6-Master-节点加入集群"><span class="nav-text">4.6 Master 节点加入集群</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#4-8-node-节点加入集群"><span class="nav-text">4.8 node 节点加入集群</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#五、集群-token-过期处理"><span class="nav-text">五、集群 token 过期处理</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#六、卸载-flannel-网络插件"><span class="nav-text">六、卸载 flannel 网络插件</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#七、卸载-k8s-集群"><span class="nav-text">七、卸载 k8s 集群</span></a></li></ol></li></ol></div></div></section><div class="back-to-top"><i class="fa fa-arrow-up"></i> <span id="scrollpercent"><span>0</span>%</span></div></div></aside></div></main><footer id="footer" class="footer"><div class="footer-inner"><script async src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script><div class="copyright">&copy; <span itemprop="copyrightYear">2023</span><span class="with-love"><i class="fa fa-user"></i></span> <span class="author" itemprop="copyrightHolder">Zhongzhou Chen</span> <span class="post-meta-divider">|</span><span class="post-meta-item-icon"><i class="fa fa-area-chart"></i></span> <span class="post-meta-item-text">Site words total count&#58;</span> <span title="Site words total count">863.9k</span></div><span class="post-meta-divider"></span></div></footer></div><script type="text/javascript">"[object Function]"!==Object.prototype.toString.call(window.Promise)&&(window.Promise=null)</script><script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script><script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script><script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script><script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script><script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script><script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script><script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script><script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script><style>.copy-btn{display:inline-block;padding:6px 12px;font-size:13px;font-weight:700;line-height:20px;color:#333;white-space:nowrap;vertical-align:middle;cursor:pointer;background-color:#eee;background-image:linear-gradient(#fcfcfc,#eee);border:1px solid #d5d5d5;border-radius:3px;user-select:none;outline:0}.highlight-wrap .copy-btn{transition:opacity .3s ease-in-out;opacity:0;padding:2px 6px;position:absolute;right:4px;top:8px}.highlight-wrap .copy-btn:focus,.highlight-wrap:hover .copy-btn{opacity:1}.highlight-wrap{position:relative}</style><script>$(".highlight").each(function(t,e){var n=$("<div>").addClass("highlight-wrap");$(e).after(n),n.append($("<button>").addClass("copy-btn").append("复制").on("click",function(t){var e=$(this).parent().find(".code").find(".line").map(function(t,e){return $(e).text()}).toArray().join("\n"),n=document.createElement("textarea");document.body.appendChild(n),n.style.position="absolute",n.style.top="0px",n.style.left="0px",n.value=e,n.select(),n.focus();var o=document.execCommand("copy");document.body.removeChild(n),o?$(this).text("复制成功"):$(this).text("复制失败"),$(this).blur()})).on("mouseleave",function(t){var e=$(this).find(".copy-btn");setTimeout(function(){e.text("复制")},300)}).append(e)})</script><script type="text/javascript" src="/js/src/affix.js?v=5.1.4"></script><script type="text/javascript" src="/js/src/schemes/pisces.js?v=5.1.4"></script><script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.4"></script><script type="text/javascript" src="/js/src/post-details.js?v=5.1.4"></script><script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script><script type="text/javascript">function proceedsearch(){$("body").append('<div class="search-popup-overlay local-search-pop-overlay"></div>').css("overflow","hidden"),$(".search-popup-overlay").click(onPopupClose),$(".popup").toggle();var t=$("#local-search-input");t.attr("autocapitalize","none"),t.attr("autocorrect","off"),t.focus()}var isfetched=!1,isXml=!0,search_path="search.xml";0===search_path.length?search_path="search.xml":/json$/i.test(search_path)&&(isXml=!1);var path="/"+search_path,onPopupClose=function(t){$(".popup").hide(),$("#local-search-input").val(""),$(".search-result-list").remove(),$("#no-result").remove(),$(".local-search-pop-overlay").remove(),$("body").css("overflow","")},searchFunc=function(t,e,s){"use strict";$("body").append('<div class="search-popup-overlay local-search-pop-overlay"><div id="search-loading-icon"><i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i></div></div>').css("overflow","hidden"),$("#search-loading-icon").css("margin","20% auto 0 auto").css("text-align","center"),$.ajax({url:t,dataType:isXml?"xml":"json",async:!0,success:function(t){isfetched=!0,$(".popup").detach().appendTo(".header-inner");var o=isXml?$("entry",t).map(function(){return{title:$("title",this).text(),content:$("content",this).text(),url:$("url",this).text()}}).get():t,n=document.getElementById(e),r=document.getElementById(s);n.addEventListener("input",function(){var y=n.value.trim().toLowerCase(),T=y.split(/[\s\-]+/);1<T.length&&T.push(y);var b=[];if(0<y.length&&o.forEach(function(t){function e(t,e,o,n){for(var r=n[n.length-1],s=r.position,a=r.word,i=[],c=0;s+a.length<=o&&0!=n.length;){a===y&&c++,i.push({position:s,length:a.length});var l=s+a.length;for(n.pop();0!=n.length&&(s=(r=n[n.length-1]).position,a=r.word,s<l);)n.pop()}return h+=c,{hits:i,start:e,end:o,searchTextCount:c}}function o(o,t){var n="",r=t.start;return t.hits.forEach(function(t){n+=o.substring(r,t.position);var e=t.position+t.length;n+='<b class="search-keyword">'+o.substring(t.position,e)+"</b>",r=e}),n+=o.substring(r,t.end)}var n=!1,r=0,h=0,s=t.title.trim(),a=s.toLowerCase(),i=t.content.trim().replace(/<[^>]+>/g,""),c=i.toLowerCase(),l=decodeURIComponent(t.url),p=[],u=[];if(""!=s&&(T.forEach(function(t){function e(t,e,o){var n=t.length;if(0===n)return[];var r=0,s=[],a=[];for(o||(e=e.toLowerCase(),t=t.toLowerCase());-1<(s=e.indexOf(t,r));)a.push({position:s,word:t}),r=s+n;return a}p=p.concat(e(t,a,!1)),u=u.concat(e(t,c,!1))}),(0<p.length||0<u.length)&&(n=!0,r=p.length+u.length)),n){[p,u].forEach(function(t){t.sort(function(t,e){return e.position!==t.position?e.position-t.position:t.word.length-e.word.length})});var f=[];0!=p.length&&f.push(e(0,0,s.length,p));for(var d=[];0!=u.length;){var g=u[u.length-1],v=g.position,$=g.word,C=v-20,m=v+80;C<0&&(C=0),m<v+$.length&&(m=v+$.length),m>i.length&&(m=i.length),d.push(e(0,C,m,u))}d.sort(function(t,e){return t.searchTextCount!==e.searchTextCount?e.searchTextCount-t.searchTextCount:t.hits.length!==e.hits.length?e.hits.length-t.hits.length:t.start-e.start});var x=parseInt("1");0<=x&&(d=d.slice(0,x));var w="";w+=0!=f.length?"<li><a href='"+l+"' class='search-result-title'>"+o(s,f[0])+"</a>":"<li><a href='"+l+"' class='search-result-title'>"+s+"</a>",d.forEach(function(t){w+="<a href='"+l+'\'><p class="search-result">'+o(i,t)+"...</p></a>"}),w+="</li>",b.push({item:w,searchTextCount:h,hitCount:r,id:b.length})}}),1===T.length&&""===T[0])r.innerHTML='<div id="no-result"><i class="fa fa-search fa-5x" /></div>';else if(0===b.length)r.innerHTML='<div id="no-result"><i class="fa fa-frown-o fa-5x" /></div>';else{b.sort(function(t,e){return t.searchTextCount!==e.searchTextCount?e.searchTextCount-t.searchTextCount:t.hitCount!==e.hitCount?e.hitCount-t.hitCount:e.id-t.id});var e='<ul class="search-result-list">';b.forEach(function(t){e+=t.item}),e+="</ul>",r.innerHTML=e}}),$(".local-search-pop-overlay").remove(),$("body").css("overflow",""),proceedsearch()}})};$(".popup-trigger").click(function(t){t.stopPropagation(),!1===isfetched?searchFunc(path,"local-search-input","local-search-result"):proceedsearch()}),$(".popup-btn-close").click(onPopupClose),$(".popup").click(function(t){t.stopPropagation()}),$(document).on("keyup",function(t){27===t.which&&$(".search-popup").is(":visible")&&onPopupClose()})</script><script type="text/javascript" src="/js/src/love.js"></script><script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({pluginRootPath:"live2dw/",pluginJsPath:"lib/",pluginModelPath:"assets/",tagMode:!1,debug:!1,log:!1,model:{jsonPath:"/live2dw/assets/shizuku.model.json"},display:{position:"right"},mobile:{show:!0,scale:.2},react:{opacityDefault:.7,opacityOnHover:.2,opacity:.4}})</script></body></html>