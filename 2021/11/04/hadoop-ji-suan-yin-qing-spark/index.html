<!DOCTYPE html><html class="theme-next gemini use-motion" lang="zh-Hans"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=1"><script src="//cdn.bootcss.com/pace/1.0.2/pace.min.js"></script><link href="//cdn.bootcss.com/pace/1.0.2/themes/pink/pace-theme-flash.css" rel="stylesheet"><script></script><meta name="theme-color" content="#222"><style>.pace .pace-progress{background:#1e92fb;height:3px}.pace .pace-progress-inner{box-shadow:0 0 10px #1e92fb,0 0 5px #1e92fb}.pace .pace-activity{border-top-color:#1e92fb;border-left-color:#1e92fb}</style><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><meta name="google-site-verification" content="HGM141IpbHrSmnAmR6W_zE4bo9Z3f-yXLeHYT3bg1fk"><meta name="baidu-site-verification" content="code-5Ai1DA8e6T"><link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css"><link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css"><link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css"><link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4"><link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.4"><link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4"><link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222"><meta name="keywords" content="Hadoop,Hadoop Spark,"><link rel="alternate" href="/atom.xml" title="凡间的精灵" type="application/atom+xml"><meta name="description" content="一、简介Apache Spark 是用于大规模数据处理的统一分析引擎。 它提供了 Java、Scala、Python 和 R 中的高级 API，以及优化的引擎，该引擎支持用于数据分析的通用计算图。 它还支持丰富的高级工具集，包括用于 SQL 和 DataFrames 的 Spark SQL，用于机器学习的 MLlib，用于图形处理的 GraphX 和用于流处理的 Spark Streaming。1"><meta name="keywords" content="Hadoop,Hadoop Spark"><meta property="og:type" content="article"><meta property="og:title" content="Hadoop 计算引擎Spark"><meta property="og:url" content="http:&#x2F;&#x2F;chenzhonzhou.github.io&#x2F;2021&#x2F;11&#x2F;04&#x2F;hadoop-ji-suan-yin-qing-spark&#x2F;index.html"><meta property="og:site_name" content="凡间的精灵"><meta property="og:description" content="一、简介Apache Spark 是用于大规模数据处理的统一分析引擎。 它提供了 Java、Scala、Python 和 R 中的高级 API，以及优化的引擎，该引擎支持用于数据分析的通用计算图。 它还支持丰富的高级工具集，包括用于 SQL 和 DataFrames 的 Spark SQL，用于机器学习的 MLlib，用于图形处理的 GraphX 和用于流处理的 Spark Streaming。1"><meta property="og:locale" content="zh-Hans"><meta property="og:image" content="http:&#x2F;&#x2F;chenzhonzhou.github.io&#x2F;2021&#x2F;11&#x2F;04&#x2F;hadoop-ji-suan-yin-qing-spark&#x2F;%E5%9B%BE%E7%89%871.png"><meta property="og:image" content="http:&#x2F;&#x2F;chenzhonzhou.github.io&#x2F;2021&#x2F;11&#x2F;04&#x2F;hadoop-ji-suan-yin-qing-spark&#x2F;%E5%9B%BE%E7%89%872.png"><meta property="og:image" content="http:&#x2F;&#x2F;chenzhonzhou.github.io&#x2F;2021&#x2F;11&#x2F;04&#x2F;hadoop-ji-suan-yin-qing-spark&#x2F;%E5%9B%BE%E7%89%873.png"><meta property="og:image" content="http:&#x2F;&#x2F;chenzhonzhou.github.io&#x2F;2021&#x2F;11&#x2F;04&#x2F;hadoop-ji-suan-yin-qing-spark&#x2F;%E5%9B%BE%E7%89%874.png"><meta property="og:image" content="http:&#x2F;&#x2F;chenzhonzhou.github.io&#x2F;2021&#x2F;11&#x2F;04&#x2F;hadoop-ji-suan-yin-qing-spark&#x2F;%E5%9B%BE%E7%89%875.png"><meta property="og:image" content="http:&#x2F;&#x2F;chenzhonzhou.github.io&#x2F;2021&#x2F;11&#x2F;04&#x2F;hadoop-ji-suan-yin-qing-spark&#x2F;%E5%9B%BE%E7%89%876.png"><meta property="og:image" content="https:&#x2F;&#x2F;pic4.zhimg.com&#x2F;80&#x2F;v2-7fd2a4e1a3e9d43a3bbfb1a2ccd152e7_720w.jpg"><meta property="og:image" content="http:&#x2F;&#x2F;chenzhonzhou.github.io&#x2F;2021&#x2F;11&#x2F;04&#x2F;hadoop-ji-suan-yin-qing-spark&#x2F;%E5%9B%BE%E7%89%8710.png"><meta property="og:image" content="http:&#x2F;&#x2F;chenzhonzhou.github.io&#x2F;2021&#x2F;11&#x2F;04&#x2F;hadoop-ji-suan-yin-qing-spark&#x2F;%E5%9B%BE%E7%89%8711.png"><meta property="og:image" content="http:&#x2F;&#x2F;chenzhonzhou.github.io&#x2F;2021&#x2F;11&#x2F;04&#x2F;hadoop-ji-suan-yin-qing-spark&#x2F;%E5%9B%BE%E7%89%879.png"><meta property="og:image" content="http:&#x2F;&#x2F;chenzhonzhou.github.io&#x2F;2021&#x2F;11&#x2F;04&#x2F;hadoop-ji-suan-yin-qing-spark&#x2F;%E5%9B%BE%E7%89%8712.png"><meta property="og:image" content="http:&#x2F;&#x2F;chenzhonzhou.github.io&#x2F;2021&#x2F;11&#x2F;04&#x2F;hadoop-ji-suan-yin-qing-spark&#x2F;%E5%9B%BE%E7%89%8713.png"><meta property="og:image" content="http:&#x2F;&#x2F;chenzhonzhou.github.io&#x2F;2021&#x2F;11&#x2F;04&#x2F;hadoop-ji-suan-yin-qing-spark&#x2F;%E5%9B%BE%E7%89%8714.png"><meta property="og:image" content="http:&#x2F;&#x2F;chenzhonzhou.github.io&#x2F;2021&#x2F;11&#x2F;04&#x2F;hadoop-ji-suan-yin-qing-spark&#x2F;%E5%9B%BE%E7%89%8715.png"><meta property="og:image" content="http:&#x2F;&#x2F;chenzhonzhou.github.io&#x2F;2021&#x2F;11&#x2F;04&#x2F;hadoop-ji-suan-yin-qing-spark&#x2F;%E5%9B%BE%E7%89%8719.png"><meta property="og:image" content="http:&#x2F;&#x2F;chenzhonzhou.github.io&#x2F;2021&#x2F;11&#x2F;04&#x2F;hadoop-ji-suan-yin-qing-spark&#x2F;%E5%9B%BE%E7%89%8717.png"><meta property="og:image" content="http:&#x2F;&#x2F;chenzhonzhou.github.io&#x2F;2021&#x2F;11&#x2F;04&#x2F;hadoop-ji-suan-yin-qing-spark&#x2F;%E5%9B%BE%E7%89%8718.png"><meta property="og:updated_time" content="2021-12-21T10:00:10.783Z"><meta name="twitter:card" content="summary"><meta name="twitter:image" content="http:&#x2F;&#x2F;chenzhonzhou.github.io&#x2F;2021&#x2F;11&#x2F;04&#x2F;hadoop-ji-suan-yin-qing-spark&#x2F;%E5%9B%BE%E7%89%871.png"><script type="text/javascript" id="hexo.configurations">var NexT=window.NexT||{},CONFIG={root:"/",scheme:"Gemini",version:"5.1.4",sidebar:{position:"left",display:"always",offset:12,b2t:!0,scrollpercent:!0,onmobile:!0},fancybox:!0,tabs:!0,motion:{enable:!0,async:!1,transition:{post_block:"fadeIn",post_header:"slideDownIn",post_body:"slideDownIn",coll_header:"slideLeftIn",sidebar:"slideUpIn"}},duoshuo:{userId:"0",author:"博主"},algolia:{applicationID:"",apiKey:"",indexName:"",hits:{per_page:10},labels:{input_placeholder:"Search for Posts",hits_empty:"We didn't find any results for the search: ${query}",hits_stats:"${hits} results found in ${time} ms"}}}</script><link rel="canonical" href="http://chenzhonzhou.github.io/2021/11/04/hadoop-ji-suan-yin-qing-spark/"><title>Hadoop 计算引擎Spark | 凡间的精灵</title><link rel="stylesheet" href="/css/prism-tomorrow.css" type="text/css"></head><body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans"><div class="container sidebar-position-left page-post-detail"><div class="headband"></div><header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="header-inner"><div class="site-brand-wrapper"><div class="site-meta"><div class="custom-logo-site-title"><a href="/" class="brand" rel="start"><span class="logo-line-before"><i></i></span> <span class="site-title">凡间的精灵</span><span class="logo-line-after"><i></i></span></a></div><p class="site-subtitle">凡尘落素一精灵</p></div><div class="site-nav-toggle"><button><span class="btn-bar"></span><span class="btn-bar"></span><span class="btn-bar"></span></button></div></div><nav class="site-nav"><ul id="menu" class="menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="menu-item-icon fa fa-fw fa-home"></i><br>首页</a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="menu-item-icon fa fa-fw fa-archive"></i><br>归档</a></li><li class="menu-item menu-item-categories"><a href="/categories" rel="section"><i class="menu-item-icon fa fa-fw fa-th"></i><br>分类</a></li><li class="menu-item menu-item-tags"><a href="/tags" rel="section"><i class="menu-item-icon fa fa-fw fa-tags"></i><br>标签</a></li><li class="menu-item menu-item-sitemap"><a href="/sitemap.xml" rel="section"><i class="menu-item-icon fa fa-fw fa-sitemap"></i><br>站点地图</a></li><li class="menu-item menu-item-search"><a href="javascript:;" class="popup-trigger"><i class="menu-item-icon fa fa-search fa-fw"></i><br>搜索</a></li></ul><div class="site-search"><div class="popup search-popup local-search-popup"><div class="local-search-header clearfix"><span class="search-icon"><i class="fa fa-search"></i></span><span class="popup-btn-close"><i class="fa fa-times-circle"></i></span><div class="local-search-input-wrapper"><input autocomplete="off" placeholder="搜索..." spellcheck="false" type="text" id="local-search-input"></div></div><div id="local-search-result"></div></div></div></nav></div></header><main id="main" class="main"><div class="main-inner"><div class="content-wrap"><div id="content" class="content"><div id="posts" class="posts-expand"><article class="post post-type-normal" itemscope itemtype="http://schema.org/Article"><div class="post-block"><link itemprop="mainEntityOfPage" href="http://chenzhonzhou.github.io/2021/11/04/hadoop-ji-suan-yin-qing-spark/"><span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="name" content="Zhongzhou Chen"><meta itemprop="description" content=""><meta itemprop="image" content="/images/chen.png"></span><span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="凡间的精灵"></span><header class="post-header"><h1 class="post-title" itemprop="name headline">Hadoop 计算引擎Spark</h1><div class="post-meta"><span class="post-time"><span class="post-meta-item-icon"><i class="fa fa-calendar-o"></i></span> <span class="post-meta-item-text">发表于</span> <time title="创建于" itemprop="dateCreated datePublished" datetime="2021-11-04T15:03:41+08:00">2021-11-04</time></span> <span class="post-category"><span class="post-meta-divider">|</span><span class="post-meta-item-icon"><i class="fa fa-folder-o"></i></span> <span class="post-meta-item-text">分类于</span> <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/Hadoop/" itemprop="url" rel="index"><span itemprop="name">Hadoop</span></a></span></span><div class="post-wordcount"><span class="post-meta-item-icon"><i class="fa fa-file-word-o"></i></span> <span class="post-meta-item-text">字数统计&#58;</span> <span title="字数统计">5.7k</span> <span class="post-meta-divider">|</span><span class="post-meta-item-icon"><i class="fa fa-clock-o"></i></span> <span class="post-meta-item-text">阅读时长 &asymp;</span> <span title="阅读时长">21</span></div></div></header><div class="post-body" itemprop="articleBody"><h2 id="一、简介"><a href="#一、简介" class="headerlink" title="一、简介"></a>一、简介</h2><p><a href="https://spark.apache.org/" target="_blank" rel="noopener">Apache Spark</a> 是用于大规模数据处理的统一分析引擎。 它提供了 Java、Scala、Python 和 R 中的高级 API，以及优化的引擎，该引擎支持用于数据分析的通用计算图。 它还支持丰富的高级工具集，包括用于 SQL 和 DataFrames 的 <a href="http://spark.apache.org/docs/latest/sql-programming-guide.html" target="_blank" rel="noopener">Spark SQL</a>，用于机器学习的 <a href="http://spark.apache.org/docs/latest/ml-guide.html" target="_blank" rel="noopener">MLlib</a>，用于图形处理的 <a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html" target="_blank" rel="noopener">GraphX</a> 和用于流处理的 <a href="http://spark.apache.org/docs/latest/structured-streaming-programming-guide.html" target="_blank" rel="noopener">Spark Streaming</a>。</p><h3 id="1-1-Spark-的特点"><a href="#1-1-Spark-的特点" class="headerlink" title="1.1 Spark 的特点"></a>1.1 Spark 的特点</h3><p><strong>高效性</strong></p><p>与Hadoop的MapReduce相比，Spark基于内存的运算要比MapReduce运算快100倍以上，基于硬盘的运算也要快10倍以上。Spark实现了高效的DAG执行引擎，可以通过基于内存来高效处理数据流。计算的中间结果是存在于内存中的。</p><p><img src="/2021/11/04/hadoop-ji-suan-yin-qing-spark/%E5%9B%BE%E7%89%871.png" alt="图片1"></p><p><strong>易用性</strong></p><p>不同于MapReduce仅支持Map和Reduce两种编程算子，Spark提供了超过80种不同的Transformation和Action算子，如map,reduce,filter,groupByKey,sortByKey,foreach等，并且采用函数式编程风格，实现相同的功能需要的代码量极大缩小。</p><p>Spark支持Java、Python和Scala的API，还支持超过80种高级算子，使用户可以快速构建不同的应用。而且Spark支持<strong>交互式</strong>的Python和Scala的shell，可以非常方便地在这些shell中使用Spark集群来验证解决问题的方法。</p><p><img src="/2021/11/04/hadoop-ji-suan-yin-qing-spark/%E5%9B%BE%E7%89%872.png" alt="图片2"></p><p><strong>通用性</strong></p><p>Spark提供了统一的解决方案。Spark可以用于批处理、交互式查询（Spark SQL）、实时流处理（Spark Streaming）、机器学习（Spark MLlib）和图计算（GraphX）。这些不同类型的处理都可以在同一个应用中无缝使用。</p><p><img src="/2021/11/04/hadoop-ji-suan-yin-qing-spark/%E5%9B%BE%E7%89%873.png" alt="图片3"></p><p><strong>兼容性</strong></p><p>Spark能够跟很多开源工程兼容使用。如Spark可以使用Hadoop的YARN和Apache Mesos作为它的资源管理和调度器，并且Spark可以读取多种数据源，如HDFS、HBase、MySQL等。</p><p><img src="/2021/11/04/hadoop-ji-suan-yin-qing-spark/%E5%9B%BE%E7%89%874.png" alt="图片4"></p><h2 id="二、Spark-架构原理"><a href="#二、Spark-架构原理" class="headerlink" title="二、Spark 架构原理"></a>二、Spark 架构原理</h2><h3 id="2-1-Spark-专业术语定义"><a href="#2-1-Spark-专业术语定义" class="headerlink" title="2.1 Spark 专业术语定义"></a>2.1 Spark 专业术语定义</h3><blockquote><p><strong>RDD：</strong>是弹性分布式数据集（Resilient Distributed Dataset）的简称，是分布式内存的一个抽象概念，提供了一种高度受限的共享内存模型。<br><strong>Application：</strong>用户编写的Spark应用程序，一个Application包含多个Job。<br><strong>DAG：</strong>是Directed Acyclic Graph（有向无环图）指的是数据转换执行的过程，有方向，无闭环（其实就是 RDD 执行的流程）。<br><strong>DAGScheduler：</strong>有向无环图调度器，基于DAG划分Stage 并以TaskSet的形势提交Stage给TaskScheduler；负责将作业拆分成不同阶段的具有依赖关系的多批任务；最重要的任务之一就是：计算作业和任务的依赖关系，制定调度逻辑。在SparkContext初始化的过程中被实例化，一个SparkContext对应创建一个DAGScheduler。<br><strong>Driver：</strong>驱动程序，Spark中的Driver即运行上述Application的Main()函数并且创建SparkContext，其中创建SparkContext的目的是为了准备Spark应用程序的运行环境。<br><strong>Driver Program：</strong>控制程序，负责为Application构建DAG图。<br><strong>Cluster Manager：</strong>集群资源管理中心，负责分配计算资源。目前有三种类型：</p><ol><li>Standalon : spark原生的资源管理，由Master负责资源的分配</li><li>Apache Mesos:与hadoop MR兼容性良好的一种资源调度框架</li><li>Hadoop Yarn: 主要是指Yarn中的ResourceManager</li></ol><p><strong>Worker：</strong>计算节点，集群中任何可以运行Application代码的节点，类似于Yarn中的NodeManager节点。<br><strong>Executor：</strong>执行器，是运行在工作节点（Worker Node）上的一个进程，负责运行Task，并为应用程序存储数据。<br><strong>Job：</strong>作业，一个Job包含多个RDD及作用于相应RDD上的各种操作。<br><strong>Stage：</strong>阶段，是作业的基本调度单位，一个作业会分为多组任务，每组任务被称为<strong>阶段</strong>。<br><strong>TaskScheduler</strong>：任务调度器，将Taskset提交给worker（集群）运行并回报结果；负责每个具体任务的实际物理调度。<br><strong>TaskSet：</strong>任务集，由一组关联的，但相互之间没有Shuffle依赖关系的任务所组成的任务集。<br><strong>Task：</strong>任务，运行在Executor上的工作单元，单个分区数据集上的最小处理流程单元，是Executor中的一个线程。</p></blockquote><p>总体如图所示</p><p><img src="/2021/11/04/hadoop-ji-suan-yin-qing-spark/%E5%9B%BE%E7%89%875.png" alt="图片5"></p><h3 id="2-2-Spark-运行流程"><a href="#2-2-Spark-运行流程" class="headerlink" title="2.2 Spark 运行流程"></a>2.2 Spark 运行流程</h3><p><img src="/2021/11/04/hadoop-ji-suan-yin-qing-spark/%E5%9B%BE%E7%89%876.png" alt="图片6"></p><blockquote><ol><li>构建Spark Application的运行环境，启动SparkContext；</li><li>SparkContext向资源管理器（可以是Standalone，Mesos，Yarn）申请运行Executor资源，并启动StandaloneExecutorbackend；</li><li>Executor向SparkContext申请Task；</li><li>SparkContext将应用程序分发给Executor；</li><li>SparkContext构建成DAG图，将DAG图分解成Stage、将Taskset发送给Task Scheduler，最后由Task Scheduler将Task发送给Executor运行；</li><li>Task在Executor上运行，运行完释放所有资源；</li></ol></blockquote><p>每个Application获取专属的executor进程，该进程在Application期间一直驻留，并以多线程方式运行Task。这种Application隔离机制是有优势的，无论是从调度角度看（每个Driver调度他自己的任务），还是从运行角度看（来自不同Application的Task运行在不同JVM中），当然这样意味着Spark Application不能跨应用程序共享数据，除非将数据写入外部存储系统</p><p>Spark与资源管理器无关，只要能够获取executor进程，并能保持相互通信就可以了</p><p>提交SparkContext的Client应该靠近Worker节点（运行Executor的节点），最好是在同一个Rack里，因为Spark Application运行过程中SparkContext和Executor之间有大量的信息交换</p><h3 id="2-3-Spark-调度原理"><a href="#2-3-Spark-调度原理" class="headerlink" title="2.3 Spark 调度原理"></a>2.3 Spark 调度原理</h3><h4 id="2-3-1-Spark-集群整体运行架构"><a href="#2-3-1-Spark-集群整体运行架构" class="headerlink" title="2.3.1 Spark 集群整体运行架构"></a>2.3.1 Spark 集群整体运行架构</h4><p><img src="https://pic4.zhimg.com/80/v2-7fd2a4e1a3e9d43a3bbfb1a2ccd152e7_720w.jpg" alt="img"></p><ul><li>Spark 集群分为 Master 节点和 Worker 节点，相当于 Hadoop 的 Master 和 Slave 节点。</li><li>Master 节点上常驻 Master 守护进程，负责管理全部的 Worker 节点。</li><li>Worker 节点上常驻 Worker 守护进程，负责与 Master 节点通信并管理 Executors。</li><li>Driver 为用户编写的 Spark 应用程序所运行的进程。Driver 程序可以运行在 Master 节点上，也可运行在 Worker 节点上，还可运行在非 Spark 集群的节点上。</li></ul><h4 id="2-3-2-Spark-调度器"><a href="#2-3-2-Spark-调度器" class="headerlink" title="2.3.2 Spark 调度器"></a>2.3.2 Spark 调度器</h4><p>Spark 中主要有两种调度器：DAGScheduler 和 TaskScheduler，DAGScheduler 主要是把一个 Job 根据 RDD 间的依赖关系，划分为多个 Stage，对于划分后的每个 Stage 都抽象为一个由多个 Task 组成的任务集（TaskSet），并交给 TaskScheduler 来进行进一步的任务调度。TaskScheduler 负责对每个具体的 Task 进行调度。</p><h5 id="DAGScheduler"><a href="#DAGScheduler" class="headerlink" title="DAGScheduler"></a><strong>DAGScheduler</strong></h5><p>当创建一个 RDD 时，每个 RDD 中包含一个或多个分区，当执行 Action 操作时，相应的产生一个 Job，而一个 Job 会根据 RDD 间的依赖关系分解为多个 Stage，每个 Stage 由多个 Task 组成（即 TaskSet），每个 Task 处理 RDD 中的一个 Partition。一个 Stage 里面所有分区的任务集合被包装为一个 TaskSet 交给 TaskScheduler 来进行任务调度。这个过程由是由 DAGScheduler 来完成的。DAGScheduler 对 RDD 的调度过程如下图所示：</p><p><img src="/2021/11/04/hadoop-ji-suan-yin-qing-spark/%E5%9B%BE%E7%89%8710.png" alt="图片10"></p><h5 id="TaskScheduler"><a href="#TaskScheduler" class="headerlink" title="TaskScheduler"></a>TaskScheduler</h5><p>DAGScheduler 将一个 TaskSet 交给 TaskScheduler 后，TaskScheduler 会为每个 TaskSet 进行任务调度，Spark 中的任务调度分为两种：FIFO（先进先出）调度和 FAIR（公平调度）调度。</p><p><strong>FIFO 调度：</strong>即谁先提交谁先执行，后面的任务需要等待前面的任务执行。这是 Spark 的默认的调度模式。</p><p><strong>FAIR 调度：</strong>支持将作业分组到池中，并为每个池设置不同的调度权重，任务可以按照权重来决定执行顺序。</p><p>在 Spark 中使用哪种调度器可通过配置<strong>spark.scheduler.mode</strong>参数来设置，可选的参数有 FAIR 和 FIFO，默认是 FIFO。</p><h4 id="2-3-3-Spark-RDD-调度过程"><a href="#2-3-3-Spark-RDD-调度过程" class="headerlink" title="2.3.3 Spark RDD 调度过程"></a>2.3.3 Spark RDD 调度过程</h4><p>如下图所示，Spark 对 RDD 执行调度的过程，创建 RDD 并生成 DAG，由 DAGScheduler 分解 DAG 为包含多个 Task（即 TaskSet）的 Stages，再将 TaskSet 发送至 TaskScheduler，由 TaskScheduler 来调度每个 Task，并分配到 Worker 节点上执行，最后得到计算结果。</p><p><img src="/2021/11/04/hadoop-ji-suan-yin-qing-spark/%E5%9B%BE%E7%89%8711.png" alt="图片11"></p><h3 id="2-4-Spark-RDD-常用函数"><a href="#2-4-Spark-RDD-常用函数" class="headerlink" title="2.4 Spark RDD 常用函数"></a>2.4 Spark RDD 常用函数</h3><h4 id="2-4-1-Transformation"><a href="#2-4-1-Transformation" class="headerlink" title="2.4.1 Transformation"></a>2.4.1 Transformation</h4><p>下表列出了 Spark 支持的一些常见转换。有关详细信息，请参阅 RDD API 文档（<a href="https://spark.apache.org/docs/latest/api/scala/org/apache/spark/rdd/RDD.html" target="_blank" rel="noopener">Scala</a>、 <a href="https://spark.apache.org/docs/latest/api/java/index.html?org/apache/spark/api/java/JavaRDD.html" target="_blank" rel="noopener">Java</a>、 <a href="https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.RDD.html#pyspark.RDD" target="_blank" rel="noopener">Python</a>、 <a href="https://spark.apache.org/docs/latest/api/R/index.html" target="_blank" rel="noopener">R</a>）和配对 RDD 函数文档（<a href="https://spark.apache.org/docs/latest/api/scala/org/apache/spark/rdd/PairRDDFunctions.html" target="_blank" rel="noopener">Scala</a>、 <a href="https://spark.apache.org/docs/latest/api/java/index.html?org/apache/spark/api/java/JavaPairRDD.html" target="_blank" rel="noopener">Java</a>）</p><table><thead><tr><th align="left">方法</th><th align="left">描述</th></tr></thead><tbody><tr><td align="left"><strong>map</strong>(<em>func</em>)</td><td align="left">对调用map的RDD数据集中的每个element都使用func，然后返回一个新的RDD，这个返回的数据集是做工的数据集</td></tr><tr><td align="left"><strong>filter</strong>(<em>func</em>)</td><td align="left">对调用filter的RDD数据集中的每个元素都使用func，然后返回一个包含使func为true的元素构成的RDD</td></tr><tr><td align="left"><strong>flatMap</strong>(<em>func</em>)</td><td align="left">和map差不多，但是flatMap生成的是多个结果</td></tr><tr><td align="left"><strong>mapPartitions</strong>(<em>func</em>)</td><td align="left">和map很像，但是map是每个element，而mapPartitions是每个partition</td></tr><tr><td align="left"><strong>mapPartitionsWithIndex</strong>(<em>func</em>)</td><td align="left">和mapPartitions很像，但是func作用的是其中一个split上，所以func中应该有index</td></tr><tr><td align="left"><strong>sample</strong>(<em>withReplacement</em>, <em>fraction</em>, <em>seed</em>)</td><td align="left">使用给定的随机数生成器种子对数据的一小部分进行采样，无论是否有替换</td></tr><tr><td align="left"><strong>union</strong>(<em>otherDataset</em>)</td><td align="left">求并集</td></tr><tr><td align="left"><strong>intersection</strong>(<em>otherDataset</em>)</td><td align="left">求交集</td></tr><tr><td align="left"><strong>distinct</strong>([<em>numPartitions</em>]))</td><td align="left">数据去重，numPartitions为可选参数，表示分配多少个partition</td></tr><tr><td align="left"><strong>groupByKey</strong>([<em>numPartitions</em>])</td><td align="left">分组函数，对类型为(K, V)数据集根据K进行分组，返回(K, lterable&lt;V&gt;)类型的数据集。numPartitions为可选参数，表示分配多少个partition</td></tr><tr><td align="left"><strong>reduceByKey</strong>(<em>func</em>, [<em>numPartitions</em>])</td><td align="left">按照key分组然后聚合</td></tr><tr><td align="left"><strong>aggregateByKey</strong>(<em>zeroValue</em>)(<em>seqOp</em>, <em>combOp</em>, [<em>numPartitions</em>])</td><td align="left">当在 (K, V) 对的数据集上调用时，返回 (K, U) 对的数据集，其中每个键的值使用给定的组合函数和中性<strong>零</strong>值聚合。允许与输入值类型不同的聚合值类型，同时避免不必要的分配。与 in 一样<code>groupByKey</code>，reduce 任务的数量可通过可选的第二个参数进行配置</td></tr><tr><td align="left"><strong>sortByKey</strong>([<em>ascending</em>], [<em>numPartitions</em>])</td><td align="left">当在 K 实现 Ordered 的 (K, V) 对数据集上调用时，返回 (K, V) 对的数据集，按布尔<code>ascending</code>参数中指定的键升序或降序排序</td></tr><tr><td align="left"><strong>join</strong>(<em>otherDataset</em>, [<em>numPartitions</em>])</td><td align="left">当有两个KV的dataset(K, V) 和 (K, W)，返回是 (K, (V, W)) 的dataset,numTasks为并发的任务数</td></tr><tr><td align="left"><strong>cogroup</strong>(<em>otherDataset</em>, [<em>numPartitions</em>])</td><td align="left">当有两个KV的dataset(K, V) 和 (K, W) ，返回的是 (K, (Seq[V], Seq[W])) 的dataset,numTasks为并发的任务数</td></tr><tr><td align="left"><strong>cartesian</strong>(<em>otherDataset</em>)</td><td align="left">当调用类型为 T 和 U 的数据集时，返回一个 (T, U) 对（所有元素对）的数据集</td></tr><tr><td align="left"><strong>pipe</strong>(<em>command</em>, <em>[envVars]</em>)</td><td align="left">通过 shell 命令（例如 Perl 或 bash 脚本）对 RDD 的每个分区进行管道传输。RDD 元素被写入进程的标准输入，输出到标准输出的行作为字符串的 RDD 返回</td></tr><tr><td align="left"><strong>coalesce</strong>(<em>numPartitions</em>)</td><td align="left">将 RDD 中的分区数减少到 numPartitions。对过滤大型数据集后更有效地运行操作很有用</td></tr><tr><td align="left"><strong>repartition</strong>(<em>numPartitions</em>)</td><td align="left">随机重组 RDD 中的数据以创建更多或更少的分区并在它们之间进行平衡。这总是在网络上打乱所有数据</td></tr><tr><td align="left"><strong>repartitionAndSortWithinPartitions</strong>(<em>partitioner</em>)</td><td align="left">根据给定的分区器对 RDD 进行重新分区，并在每个结果分区内，按键对记录进行排序。这比<code>repartition</code>在每个分区内调用然后排序更有效，因为它可以将排序下推到 shuffle 机器中</td></tr></tbody></table><h4 id="2-4-2-Actions"><a href="#2-4-2-Actions" class="headerlink" title="2.4.2 Actions"></a>2.4.2 Actions</h4><table><thead><tr><th align="left">方法</th><th align="left">描述</th></tr></thead><tbody><tr><td align="left"><strong>reduce</strong>(<em>func</em>)</td><td align="left">使用函数<em>func</em>（它接受两个参数并返回一个）聚合数据集的元素。该函数应该是可交换的和关联的</td></tr><tr><td align="left"><strong>collect</strong>()</td><td align="left">在驱动程序中将数据集的所有元素作为数组返回。这通常在filter或其他返回足够小的数据子集的操作之后很有用</td></tr><tr><td align="left"><strong>count</strong>()</td><td align="left">返回数据集中元素的数量</td></tr><tr><td align="left"><strong>first</strong>()</td><td align="left">返回数据集的第一个元素（类似于 take(1)）</td></tr><tr><td align="left"><strong>take</strong>(<em>n</em>)</td><td align="left">返回一个包含数据集前 n 个元素的数组</td></tr><tr><td align="left"><strong>takeSample</strong>(<em>withReplacement</em>, <em>num</em>, [<em>seed</em>])</td><td align="left">随机取num个样本，withReplacement是否允许重复样本，num抽样个数，seed随机数种子</td></tr><tr><td align="left"><strong>takeOrdered</strong>(<em>n</em>, <em>[ordering]</em>)</td><td align="left">使用自然顺序或自定义比较器返回RDD的前 n 个元素</td></tr><tr><td align="left"><strong>saveAsTextFile</strong>(<em>path</em>)</td><td align="left">将数据集的元素作为文本文件（或一组文本文件）写入本地文件系统、HDFS 或任何其他 Hadoop 支持的文件系统中的给定目录中。Spark 将对每个元素调用 toString 以将其转换为文件中的一行文本</td></tr><tr><td align="left"><strong>saveAsSequenceFile</strong>(<em>path</em>) (Java and Scala)</td><td align="left">将数据集的元素作为 Hadoop SequenceFile 写入本地文件系统、HDFS 或任何其他 Hadoop 支持的文件系统中的给定路径中。这在实现 Hadoop 的 Writable 接口的键值对的 RDD 上可用。在 Scala 中，它也可用于隐式转换为 Writable 的类型（Spark 包括对 Int、Double、String 等基本类型的转换）</td></tr><tr><td align="left"><strong>saveAsObjectFile</strong>(<em>path</em>) (Java and Scala)</td><td align="left">使用 Java 序列化以简单格式编写数据集的元素，然后可以使用 <code>SparkContext.objectFile()</code></td></tr><tr><td align="left"><strong>countByKey</strong>()</td><td align="left">仅适用于 (K, V) 类型的 RDD。返回 (K, Int) 对的哈希图，其中包含每个键的计数</td></tr><tr><td align="left"><strong>foreach</strong>(<em>func</em>)</td><td align="left">对数据集的每个元素运行函数func</td></tr></tbody></table><h2 id="三、Spark-运行模式"><a href="#三、Spark-运行模式" class="headerlink" title="三、Spark 运行模式"></a>三、Spark 运行模式</h2><p><img src="/2021/11/04/hadoop-ji-suan-yin-qing-spark/%E5%9B%BE%E7%89%879.png" alt="图片9"></p><p>Spark 有多种运行模式，由图中可以看到 Spark 支持本地运行模式（Local 模式）、独立运行模式（Standalone 模式）、Mesos、YARN（Yet Another Resource Negotiator）、Kubernetes 模式等。</p><p><strong>本地运行模式</strong>是 Spark 中最简单的一种模式，也可称作伪分布式模式。</p><p><strong>独立运行模式</strong>为 Spark 自带的一种集群管理模式，<strong>Mesos</strong> 及 <strong>YARN</strong> 两种模式也是比较常用的集群管理模式。相比较 Mesos 及 YARN 两种模式而言，独立运行模式是最简单，也最容易部署的一种集群运行模式。</p><p><strong>Kubernetes</strong> 是一个用于自动化部署、扩展和管理容器化应用程序的开源系统。</p><p>Spark 底层还支持多种数据源，能够从其它文件系统读取数据，如 HDFS、Amazon S3、Hypertable、HBase 等。Spark 对这些文件系统的支持，同时也丰富了整个 Spark 生态的运行环境。</p><h3 id="3-1-Spark-Local-模式"><a href="#3-1-Spark-Local-模式" class="headerlink" title="3.1 Spark Local 模式"></a>3.1 Spark Local 模式</h3><p>Spark Local模式被称为Local[N]模式，是用单机的多个线程来模拟Spark分布式计算，直接运行在本地，便于调试，通常用来验证开发出来的应用程序逻辑上有没有问题，其中N代表可以使用N个线程，每个线程拥有一个core。如果不指定N，则默认是1个线程（该线程有1个core），如果是local[*]，则代表 <code>Run Spark locally with as many worker threads as logical cores on your machine.</code>即运行的线程数与CPU的核数一样。通常，Local模式用于完成开发出来的分布式程序的测试工作，并不用于实际生产。</p><h3 id="3-2-Spark-Standalone-模式"><a href="#3-2-Spark-Standalone-模式" class="headerlink" title="3.2 Spark Standalone 模式"></a>3.2 Spark Standalone 模式</h3><p>Standalone模式是Spark实现的资源调度框架，其自带完整的服务，可单独部署到一个集群中，无需依赖任何其他资源管理系统。主要的节点有Client节点、Master节点和Worker节点。其中Driver既可以运行在Master节点上中，也可以运行在本地Client端。</p><ul><li>当用<strong>spark-shell</strong>交互式工具提交Spark的Job时，Driver在Master节点上运行；</li><li>当使用<strong>spark-submit</strong>工具提交Job或者在Eclipse、IDEA等开发平台上使用 <code>new SparkConf().setMaster(“spark://master:7077”)</code> 方式运行Spark任务时，Driver是运行在本地Client端上的。</li></ul><p><img src="/2021/11/04/hadoop-ji-suan-yin-qing-spark/%E5%9B%BE%E7%89%8712.png" alt="图片12"></p><p><strong>Spark Standalone运行流程</strong></p><blockquote><p>1.SparkContext连接到Master，向Master注册并申请资源（CPU Core 和Memory）；<br>2.Master根据SparkContext的资源申请要求和Worker心跳周期内报告的信息决定在哪个Worker上分配资源，然后在该Worker上获取资源，然后启动StandaloneExecutorBackend；<br>3.StandaloneExecutorBackend向SparkContext注册；<br>4.SparkContext将Applicaiton代码发送给StandaloneExecutorBackend；并且SparkContext解析Applicaiton代码，构建DAG图，并提交给DAG Scheduler分解成Stage（当碰到Action操作时，就会催生Job；每个Job中含有1个或多个Stage，Stage一般在获取外部数据和shuffle之前产生），DAG Scheduler将TaskSet提交给Task Scheduler，Task Scheduler负责将Task分配到相应的Worker，最后提交给StandaloneExecutorBackend执行；<br>5.StandaloneExecutorBackend会建立Executor线程池，开始执行Task，并向SparkContext报告，直至Task完成；<br>6.所有Task完成后，SparkContext向Master注销，释放资源。</p></blockquote><h3 id="3-3-Spark-on-Mesos-模式"><a href="#3-3-Spark-on-Mesos-模式" class="headerlink" title="3.3 Spark on Mesos 模式"></a>3.3 Spark on Mesos 模式</h3><p>Spark On Mesos模式是很多公司采用的模式，Spark运行在Mesos上会比运行在YARN上更加灵活，更加自然。在Spark On Mesos环境中，用户可选择粗粒度模式和细粒度模式两种调度模式之一运行自己的应用程序。其中细粒度模式于Spark2.0.0版本开始不再使用。</p><p>Spark执行程序的大小取决于以下配置变量：</p><blockquote><p>执行器内存：spark.executor.memory<br>执行器核心：spark.executor.cores<br>执行者核数：spark.cores.max/spark.executor.cores</p></blockquote><h4 id="粗粒度模式-Coarse-grained-Mode"><a href="#粗粒度模式-Coarse-grained-Mode" class="headerlink" title="粗粒度模式 (Coarse-grained Mode)"></a>粗粒度模式 (Coarse-grained Mode)</h4><p>粗粒度模式下，每个应用程序的运行环境由一个Dirver和若干个Executor组成，其中，每个Executor占用若干资源，内部可运行多个Task（对应多少个<strong>slot</strong>）。应用程序的各个任务正式运行之前，需要将运行环境中的资源全部申请好，且运行过程中要一直占用这些资源，即使不用，最后程序运行结束后，回收这些资源。举个例子，比如你提交应用程序时，指定使用5个executor运行你的应用程序，每个executor占用5GB内存和5个CPU，每个executor内部设置了5个slot，则Mesos需要先为executor分配资源并启动它们，之后开始调度任务。另外，在程序运行过程中，mesos的master和slave并不知道executor内部各个task的运行情况，executor直接将任务状态通过内部的通信机制汇报给Driver，从一定程度上可以认为，每个应用程序利用mesos搭建了一个虚拟集群自己使用。</p><p><img src="/2021/11/04/hadoop-ji-suan-yin-qing-spark/%E5%9B%BE%E7%89%8713.png" alt="图片13"></p><h4 id="细粒度模式-Fine-grained-Mode"><a href="#细粒度模式-Fine-grained-Mode" class="headerlink" title="细粒度模式  (Fine-grained Mode)"></a>细粒度模式 (Fine-grained Mode)</h4><p>鉴于粗粒度模式会造成大量资源浪费，Spark On YARN还提供了另外一种调度模式：细粒度模式，这种模式类似于现在的云计算，思想是按需分配。与粗粒度模式一样，应用程序启动时，先会启动executor，但每个executor占用资源仅仅是自己运行所需的资源，不需要考虑将来要运行的任务，之后，mesos会为每个executor动态分配资源，每分配一些，便可以运行一个新任务，单个Task运行完之后可以马上释放对应的资源。每个Task会汇报状态给Mesos slave和Mesos Master，便于更加细粒度管理和容错，这种调度模式类似于MapReduce调度模式，每个Task完全独立，优点是便于资源控制和隔离，但缺点也很明显，短作业运行延迟大。</p><p><img src="/2021/11/04/hadoop-ji-suan-yin-qing-spark/%E5%9B%BE%E7%89%8714.png" alt="图片14"></p><h3 id="3-4-Spark-on-YARN模式"><a href="#3-4-Spark-on-YARN模式" class="headerlink" title="3.4 Spark on YARN模式"></a>3.4 Spark on YARN模式</h3><p>Spark On YARN模式。这是一种最有前景的部署模式。但限于YARN自身的发展，目前仅支持粗粒度模式（Coarse-grained Mode）。这是由于YARN上的Container资源是不可以动态伸缩的，一旦Container启动之后，可使用的资源不能再发生变化，不过这个已经在YARN计划（具体参考：<a href="https://issues.apache.org/jira/browse/YARN-1197" target="_blank" rel="noopener">https://issues.apache.org/jira/browse/YARN-1197</a> ）中了。</p><p>Spark on YARN模式根据Driver在集群中的位置分为两种模式：一种是YARN-Client模式，另一种是YARN-Cluster（或称为YARN-Standalone模式）。</p><h4 id="YARN-Client-模式"><a href="#YARN-Client-模式" class="headerlink" title="YARN-Client 模式"></a>YARN-Client 模式</h4><p>Yarn-Client模式中，Driver在客户端本地运行，这种模式可以使得Spark Application和客户端进行交互，因为Driver在客户端，所以可以通过webUI访问Driver的状态，默认是 <a href="http://hadoop1:4040" target="_blank" rel="noopener">http://hadoop1:4040</a> 访问，而YARN通过 <a href="http://hadoop1:8088" target="_blank" rel="noopener">http://hadoop1:8088</a> 访问。</p><p><img src="/2021/11/04/hadoop-ji-suan-yin-qing-spark/%E5%9B%BE%E7%89%8715.png" alt="图片15"></p><p><strong>YARN-client的工作流程</strong></p><blockquote><p>1.Spark Yarn Client向YARN的ResourceManager申请启动Application Master。同时在SparkContent初始化中将创建DAGScheduler和TASKScheduler等，由于我们选择的是Yarn-Client模式，程序会选择YarnClientClusterScheduler和YarnClientSchedulerBackend；<br>2.ResourceManager收到请求后，在集群中选择一个NodeManager，为该应用程序分配第一个Container，要求它在这个Container中启动应用程序的ApplicationMaster，与YARN-Cluster区别的是在该ApplicationMaster不运行SparkContext，只与SparkContext进行联系进行资源的分派；<br>3.Client中的SparkContext初始化完毕后，与ApplicationMaster建立通讯，向ResourceManager注册，根据任务信息向ResourceManager申请资源（Container）；<br>4.一旦ApplicationMaster申请到资源（也就是Container）后，便与对应的NodeManager通信，要求它在获得的Container中启动启动CoarseGrainedExecutorBackend，CoarseGrainedExecutorBackend启动后会向Client中的SparkContext注册并申请Task；<br>5.Client中的SparkContext分配Task给CoarseGrainedExecutorBackend执行，CoarseGrainedExecutorBackend运行Task并向Driver汇报运行的状态和进度，以让Client随时掌握各个任务的运行状态，从而可以在任务失败时重新启动任务；<br>6.应用程序运行完成后，Client的SparkContext向ResourceManager申请注销并关闭自己。</p></blockquote><h4 id="YARN-Cluster-模式"><a href="#YARN-Cluster-模式" class="headerlink" title="YARN-Cluster 模式"></a>YARN-Cluster 模式</h4><p>在YARN-Cluster模式中，当用户向YARN中提交一个应用程序后，YARN将分两个阶段运行该应用程序：第一个阶段是把Spark的Driver作为一个ApplicationMaster在YARN集群中先启动；第二个阶段是由ApplicationMaster创建应用程序，然后为它向ResourceManager申请资源，并启动Executor来运行Task，同时监控它的整个运行过程，直到运行完成。</p><p><img src="/2021/11/04/hadoop-ji-suan-yin-qing-spark/%E5%9B%BE%E7%89%8719.png" alt="图片19"></p><p><strong>YARN-cluster的工作流程</strong></p><blockquote><p>1.Spark Yarn Client向YARN中提交应用程序，包括ApplicationMaster程序、启动ApplicationMaster的命令、需要在Executor中运行的程序等；<br>2.ResourceManager收到请求后，在集群中选择一个NodeManager，为该应用程序分配第一个Container，要求它在这个<strong>Container中启动应用程序</strong>的ApplicationMaster，其中ApplicationMaster进行<strong>SparkContext等的初始化</strong>；<br>3.ApplicationMaster向<strong>ResourceManager注册</strong>，这样用户可以直接通过ResourceManage查看应用程序的<strong>运行状态</strong>，然后它将采用轮询的方式通过RPC协议为各个任务申请资源，并监控它们的运行状态直到运行结束；<br>4.一旦ApplicationMaster申请到资源（也就是Container）后，便与对应的NodeManager通信，要求它在获得的Container<strong>中启动CoarseGrainedExecutorBackend</strong>，CoarseGrainedExecutorBackend启动后会向ApplicationMaster中的SparkContext注册并申请Task。这一点和Standalone模式一样，只不过SparkContext在Spark Application中初始化时，使用CoarseGrainedSchedulerBackend配合YarnClusterScheduler进行任务的调度，其中YarnClusterScheduler只是对TaskSchedulerImpl的一个简单包装，增加了对Executor的等待逻辑等；<br>5.ApplicationMaster中的SparkContext<strong>分配Task</strong>给CoarseGrainedExecutorBackend执行，CoarseGrainedExecutorBackend运行Task并向ApplicationMaster汇报运行的状态和进度，以让ApplicationMaster随时掌握各个任务的运行状态，从而可以在任务失败时重新启动任务；<br>6.应用程序运行完成后，ApplicationMaster向ResourceManager申请注销并关闭自己。</p></blockquote><h4 id="YARN-Client-与-YARN-Cluster-区别"><a href="#YARN-Client-与-YARN-Cluster-区别" class="headerlink" title="YARN-Client 与 YARN-Cluster 区别"></a>YARN-Client 与 YARN-Cluster 区别</h4><p>YARN-Client模式下，Application Master仅仅向YARN请求Executor，Client会和请求的Container通信来调度他们工作，也就是说Client不能离开。</p><p><img src="/2021/11/04/hadoop-ji-suan-yin-qing-spark/%E5%9B%BE%E7%89%8717.png" alt="图片17"></p><p>YARN-Cluster模式下，Driver运行在AM(Application Master)中，它负责向YARN申请资源，并监督作业的运行状况。当用户提交了作业之后，就可以关掉Client，作业会继续在YARN上运行，因而YARN-Cluster模式不适合运行交互类型的作业；</p><p><img src="/2021/11/04/hadoop-ji-suan-yin-qing-spark/%E5%9B%BE%E7%89%8718.png" alt="图片18"></p><script>document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });</script></div><div><div><div style="text-align:center;color:#ccc;font-size:14px">-------------本文结束<i class="fa fa-paw"></i>感谢您的阅读-------------</div></div></div><div></div><footer class="post-footer"><div class="post-tags"><a href="/tags/Hadoop/" rel="tag"><i class="fa fa-tag"></i> Hadoop</a><a href="/tags/Hadoop-Spark/" rel="tag"><i class="fa fa-tag"></i> Hadoop Spark</a></div><div class="post-nav"><div class="post-nav-next post-nav-item"><a href="/2021/11/01/hadoop-liu-shi-ji-suan-yin-qing-storm/" rel="next" title="Hadoop 流式计算引擎Storm"><i class="fa fa-chevron-left"></i> Hadoop 流式计算引擎Storm</a></div><span class="post-nav-divider"></span><div class="post-nav-prev post-nav-item"><a href="/2021/11/11/spark-chang-yong-de-ji-chong-mo-shi-bu-shu/" rel="prev" title="Spark 常用的几种模式部署">Spark 常用的几种模式部署<i class="fa fa-chevron-right"></i></a></div></div></footer></div></article><div class="post-spread"><div class="jiathis_style"><span class="jiathis_txt">分享到：</span> <a class="jiathis_button_fav">收藏夹</a> <a class="jiathis_button_copy">复制网址</a> <a class="jiathis_button_email">邮件</a> <a class="jiathis_button_weixin">微信</a> <a class="jiathis_button_qzone">QQ空间</a> <a class="jiathis_button_tqq">腾讯微博</a> <a class="jiathis_button_douban">豆瓣</a> <a class="jiathis_button_share">一键分享</a> <a href="http://www.jiathis.com/share?uid=2140465" class="jiathis jiathis_txt jiathis_separator jtico jtico_jiathis" target="_blank">更多</a><a class="jiathis_counter_style"></a></div><script type="text/javascript">var jiathis_config={data_track_clickback:!0,summary:"",shortUrl:!1,hideMore:!1}</script><script type="text/javascript" src="http://v3.jiathis.com/code/jia.js?uid=" charset="utf-8"></script></div></div></div></div><div class="sidebar-toggle"><div class="sidebar-toggle-line-wrap"><span class="sidebar-toggle-line sidebar-toggle-line-first"></span><span class="sidebar-toggle-line sidebar-toggle-line-middle"></span><span class="sidebar-toggle-line sidebar-toggle-line-last"></span></div></div><aside id="sidebar" class="sidebar"><div id="sidebar-dimmer"></div><div class="sidebar-inner"><ul class="sidebar-nav motion-element"><li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">文章目录</li><li class="sidebar-nav-overview" data-target="site-overview-wrap">站点概览</li></ul><section class="site-overview-wrap sidebar-panel"><div class="site-overview"><div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person"><img class="site-author-image" itemprop="image" src="/images/chen.png" alt="Zhongzhou Chen"><p class="site-author-name" itemprop="name">Zhongzhou Chen</p><p class="site-description motion-element" itemprop="description"></p></div><nav class="site-state motion-element"><div class="site-state-item site-state-posts"><a href="/archives/%7C%7C%20archive"><span class="site-state-item-count">371</span> <span class="site-state-item-name">日志</span></a></div><div class="site-state-item site-state-categories"><a href="/categories/index.html"><span class="site-state-item-count">89</span> <span class="site-state-item-name">分类</span></a></div><div class="site-state-item site-state-tags"><a href="/tags/index.html"><span class="site-state-item-count">188</span> <span class="site-state-item-name">标签</span></a></div></nav><div class="feed-link motion-element"><a href="/atom.xml" rel="alternate"><i class="fa fa-rss"></i> RSS</a></div></div></section><section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active"><div class="post-toc"><div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#一、简介"><span class="nav-text">一、简介</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#1-1-Spark-的特点"><span class="nav-text">1.1 Spark 的特点</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#二、Spark-架构原理"><span class="nav-text">二、Spark 架构原理</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#2-1-Spark-专业术语定义"><span class="nav-text">2.1 Spark 专业术语定义</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-2-Spark-运行流程"><span class="nav-text">2.2 Spark 运行流程</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-3-Spark-调度原理"><span class="nav-text">2.3 Spark 调度原理</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#2-3-1-Spark-集群整体运行架构"><span class="nav-text">2.3.1 Spark 集群整体运行架构</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#2-3-2-Spark-调度器"><span class="nav-text">2.3.2 Spark 调度器</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#DAGScheduler"><span class="nav-text">DAGScheduler</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#TaskScheduler"><span class="nav-text">TaskScheduler</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#2-3-3-Spark-RDD-调度过程"><span class="nav-text">2.3.3 Spark RDD 调度过程</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-4-Spark-RDD-常用函数"><span class="nav-text">2.4 Spark RDD 常用函数</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#2-4-1-Transformation"><span class="nav-text">2.4.1 Transformation</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#2-4-2-Actions"><span class="nav-text">2.4.2 Actions</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#三、Spark-运行模式"><span class="nav-text">三、Spark 运行模式</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#3-1-Spark-Local-模式"><span class="nav-text">3.1 Spark Local 模式</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3-2-Spark-Standalone-模式"><span class="nav-text">3.2 Spark Standalone 模式</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3-3-Spark-on-Mesos-模式"><span class="nav-text">3.3 Spark on Mesos 模式</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#粗粒度模式-Coarse-grained-Mode"><span class="nav-text">粗粒度模式 (Coarse-grained Mode)</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#细粒度模式-Fine-grained-Mode"><span class="nav-text">细粒度模式 (Fine-grained Mode)</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3-4-Spark-on-YARN模式"><span class="nav-text">3.4 Spark on YARN模式</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#YARN-Client-模式"><span class="nav-text">YARN-Client 模式</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#YARN-Cluster-模式"><span class="nav-text">YARN-Cluster 模式</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#YARN-Client-与-YARN-Cluster-区别"><span class="nav-text">YARN-Client 与 YARN-Cluster 区别</span></a></li></ol></li></ol></li></ol></div></div></section><div class="back-to-top"><i class="fa fa-arrow-up"></i> <span id="scrollpercent"><span>0</span>%</span></div></div></aside></div></main><footer id="footer" class="footer"><div class="footer-inner"><script async src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script><div class="copyright">&copy; <span itemprop="copyrightYear">2023</span><span class="with-love"><i class="fa fa-user"></i></span> <span class="author" itemprop="copyrightHolder">Zhongzhou Chen</span> <span class="post-meta-divider">|</span><span class="post-meta-item-icon"><i class="fa fa-area-chart"></i></span> <span class="post-meta-item-text">Site words total count&#58;</span> <span title="Site words total count">863.9k</span></div><span class="post-meta-divider"></span></div></footer></div><script type="text/javascript">"[object Function]"!==Object.prototype.toString.call(window.Promise)&&(window.Promise=null)</script><script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script><script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script><script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script><script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script><script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script><script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script><script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script><script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script><style>.copy-btn{display:inline-block;padding:6px 12px;font-size:13px;font-weight:700;line-height:20px;color:#333;white-space:nowrap;vertical-align:middle;cursor:pointer;background-color:#eee;background-image:linear-gradient(#fcfcfc,#eee);border:1px solid #d5d5d5;border-radius:3px;user-select:none;outline:0}.highlight-wrap .copy-btn{transition:opacity .3s ease-in-out;opacity:0;padding:2px 6px;position:absolute;right:4px;top:8px}.highlight-wrap .copy-btn:focus,.highlight-wrap:hover .copy-btn{opacity:1}.highlight-wrap{position:relative}</style><script>$(".highlight").each(function(t,e){var n=$("<div>").addClass("highlight-wrap");$(e).after(n),n.append($("<button>").addClass("copy-btn").append("复制").on("click",function(t){var e=$(this).parent().find(".code").find(".line").map(function(t,e){return $(e).text()}).toArray().join("\n"),n=document.createElement("textarea");document.body.appendChild(n),n.style.position="absolute",n.style.top="0px",n.style.left="0px",n.value=e,n.select(),n.focus();var o=document.execCommand("copy");document.body.removeChild(n),o?$(this).text("复制成功"):$(this).text("复制失败"),$(this).blur()})).on("mouseleave",function(t){var e=$(this).find(".copy-btn");setTimeout(function(){e.text("复制")},300)}).append(e)})</script><script type="text/javascript" src="/js/src/affix.js?v=5.1.4"></script><script type="text/javascript" src="/js/src/schemes/pisces.js?v=5.1.4"></script><script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.4"></script><script type="text/javascript" src="/js/src/post-details.js?v=5.1.4"></script><script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script><script type="text/javascript">function proceedsearch(){$("body").append('<div class="search-popup-overlay local-search-pop-overlay"></div>').css("overflow","hidden"),$(".search-popup-overlay").click(onPopupClose),$(".popup").toggle();var t=$("#local-search-input");t.attr("autocapitalize","none"),t.attr("autocorrect","off"),t.focus()}var isfetched=!1,isXml=!0,search_path="search.xml";0===search_path.length?search_path="search.xml":/json$/i.test(search_path)&&(isXml=!1);var path="/"+search_path,onPopupClose=function(t){$(".popup").hide(),$("#local-search-input").val(""),$(".search-result-list").remove(),$("#no-result").remove(),$(".local-search-pop-overlay").remove(),$("body").css("overflow","")},searchFunc=function(t,e,s){"use strict";$("body").append('<div class="search-popup-overlay local-search-pop-overlay"><div id="search-loading-icon"><i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i></div></div>').css("overflow","hidden"),$("#search-loading-icon").css("margin","20% auto 0 auto").css("text-align","center"),$.ajax({url:t,dataType:isXml?"xml":"json",async:!0,success:function(t){isfetched=!0,$(".popup").detach().appendTo(".header-inner");var o=isXml?$("entry",t).map(function(){return{title:$("title",this).text(),content:$("content",this).text(),url:$("url",this).text()}}).get():t,n=document.getElementById(e),r=document.getElementById(s);n.addEventListener("input",function(){var y=n.value.trim().toLowerCase(),T=y.split(/[\s\-]+/);1<T.length&&T.push(y);var b=[];if(0<y.length&&o.forEach(function(t){function e(t,e,o,n){for(var r=n[n.length-1],s=r.position,a=r.word,i=[],c=0;s+a.length<=o&&0!=n.length;){a===y&&c++,i.push({position:s,length:a.length});var l=s+a.length;for(n.pop();0!=n.length&&(s=(r=n[n.length-1]).position,a=r.word,s<l);)n.pop()}return h+=c,{hits:i,start:e,end:o,searchTextCount:c}}function o(o,t){var n="",r=t.start;return t.hits.forEach(function(t){n+=o.substring(r,t.position);var e=t.position+t.length;n+='<b class="search-keyword">'+o.substring(t.position,e)+"</b>",r=e}),n+=o.substring(r,t.end)}var n=!1,r=0,h=0,s=t.title.trim(),a=s.toLowerCase(),i=t.content.trim().replace(/<[^>]+>/g,""),c=i.toLowerCase(),l=decodeURIComponent(t.url),p=[],u=[];if(""!=s&&(T.forEach(function(t){function e(t,e,o){var n=t.length;if(0===n)return[];var r=0,s=[],a=[];for(o||(e=e.toLowerCase(),t=t.toLowerCase());-1<(s=e.indexOf(t,r));)a.push({position:s,word:t}),r=s+n;return a}p=p.concat(e(t,a,!1)),u=u.concat(e(t,c,!1))}),(0<p.length||0<u.length)&&(n=!0,r=p.length+u.length)),n){[p,u].forEach(function(t){t.sort(function(t,e){return e.position!==t.position?e.position-t.position:t.word.length-e.word.length})});var f=[];0!=p.length&&f.push(e(0,0,s.length,p));for(var d=[];0!=u.length;){var g=u[u.length-1],v=g.position,$=g.word,C=v-20,m=v+80;C<0&&(C=0),m<v+$.length&&(m=v+$.length),m>i.length&&(m=i.length),d.push(e(0,C,m,u))}d.sort(function(t,e){return t.searchTextCount!==e.searchTextCount?e.searchTextCount-t.searchTextCount:t.hits.length!==e.hits.length?e.hits.length-t.hits.length:t.start-e.start});var x=parseInt("1");0<=x&&(d=d.slice(0,x));var w="";w+=0!=f.length?"<li><a href='"+l+"' class='search-result-title'>"+o(s,f[0])+"</a>":"<li><a href='"+l+"' class='search-result-title'>"+s+"</a>",d.forEach(function(t){w+="<a href='"+l+'\'><p class="search-result">'+o(i,t)+"...</p></a>"}),w+="</li>",b.push({item:w,searchTextCount:h,hitCount:r,id:b.length})}}),1===T.length&&""===T[0])r.innerHTML='<div id="no-result"><i class="fa fa-search fa-5x" /></div>';else if(0===b.length)r.innerHTML='<div id="no-result"><i class="fa fa-frown-o fa-5x" /></div>';else{b.sort(function(t,e){return t.searchTextCount!==e.searchTextCount?e.searchTextCount-t.searchTextCount:t.hitCount!==e.hitCount?e.hitCount-t.hitCount:e.id-t.id});var e='<ul class="search-result-list">';b.forEach(function(t){e+=t.item}),e+="</ul>",r.innerHTML=e}}),$(".local-search-pop-overlay").remove(),$("body").css("overflow",""),proceedsearch()}})};$(".popup-trigger").click(function(t){t.stopPropagation(),!1===isfetched?searchFunc(path,"local-search-input","local-search-result"):proceedsearch()}),$(".popup-btn-close").click(onPopupClose),$(".popup").click(function(t){t.stopPropagation()}),$(document).on("keyup",function(t){27===t.which&&$(".search-popup").is(":visible")&&onPopupClose()})</script><script type="text/javascript" src="/js/src/love.js"></script><script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({pluginRootPath:"live2dw/",pluginJsPath:"lib/",pluginModelPath:"assets/",tagMode:!1,debug:!1,log:!1,model:{jsonPath:"/live2dw/assets/shizuku.model.json"},display:{position:"right"},mobile:{show:!0,scale:.2},react:{opacityDefault:.7,opacityOnHover:.2,opacity:.4}})</script></body></html>